# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements. See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License. You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

sudo: required

dist: trusty

cache:
  directories:
  - $HOME/.m2

install: true

language: java

branches:
  only:
   - master

env:
  global:
    - JAVA_OPTS=-Xmx3g
    - TEST_MODULES=":mahout-hdfs,:mahout-math"
    - STANDARD_BUILD_OPTS="-Dmaven.javadoc.skip=true -B -V"
    - PROFILES="-Ptravis"
    - SPARK_1_6=http://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz
    - SPARK_2_0=http://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz
    - SPARK_2_1=http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz

# The file assumes a certain build order for the maven / nightly build deployments.
matrix:
  include:
    # Build Spark 1.6.3 , Scala 2.10
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.10,spark-1.6" SPARK_BIN=$SPARK_1_6 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.10,:mahout-spark_1.6_2.10"

    # Build Spark 2.0.2 , Scala 2.11
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.11,spark-2.0" SPARK_BIN=$SPARK_2_0 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.0_2.11"

    # Build Spark 2.1.0 , Scala 2.11
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pspark-2.1,scala-2.11" SPARK_BIN=$SPARK_2_1 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.1_2.11"

    # Build Spark 1.6.3 , Scala 2.10, ViennaCL
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.10,spark-1.6,viennacl" SPARK_BIN=$SPARK_1_6 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.10,:mahout-spark_1.6_2.10" # we don't test viennacl on travis

    # Build Spark 2.0.2 , Scala 2.11, ViennaCL
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.11,spark-2.0,viennacl" SPARK_BIN=$SPARK_2_0 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.0_2.11" # we don't test viennacl on travis

    # Build Spark 2.1.0 , Scala 2.11, ViennaCL
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.11,spark-2.1,viennacl" SPARK_BIN=$SPARK_2_1 TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.1_2.11" # we don't test viennacl on travis

    # Build Spark 1.6.3 , Scala 2.10, ViennaCL-OMP
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.10,spark-1.6,viennacl-omp" TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.10,:mahout-spark_1.6_2.10,:mahout-native-viennacl-omp_2.10" SPARK_BIN=$SPARK_1_6

    # Build Spark 2.0.2 , Scala 2.11, ViennaCL-OMP
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.11,spark-2.0,viennacl-omp" TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.0_2.11,:mahout-native-viennacl-omp_2.11" SPARK_BIN=$SPARK_2_0

    # Build Spark 2.1.0 , Scala 2.11, ViennaCL-OMP
    - jdk: "openjdk7"
      env: PROFILES="${PROFILES} -Pscala-2.11,spark-2.1,viennacl-omp" TEST_MODULES="${TEST_MODULES},:mahout-math-scala_2.11,:mahout-spark_2.1_2.11,:mahout-native-viennacl-omp_2.11" SPARK_BIN=$SPARK_2_1

git:
  depth: 10

#notifications:
#  slack: mahout:7vlbihiCBKuhEZK2610jkeeT

before_install:
# Install Maven 3.3.x+
  - wget https://archive.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip
  - unzip -qq apache-maven-3.3.9-bin.zip
  - export M2_HOME=$PWD/apache-maven-3.3.9
  - export PATH=$M2_HOME/bin:$PATH
  - export MAHOUT_HOME=$PWD
  - sudo apt-get -qq update
  # Install OpenCL Driver
  - sudo apt-get install ocl-icd-libopencl1
  # Install ViennaCL Source
  - wget https://github.com/viennacl/viennacl-dev/archive/release-1.7.1.zip
  - unzip -qq release-1.7.1.zip
  - sudo cp -r viennacl-dev-release-1.7.1/viennacl /usr/include/viennacl
  - sudo cp -r viennacl-dev-release-1.7.1/CL /usr/include/CL
  # Install SSH Host Client so Spark Pseudo-cluster can start w/out password
  - sudo apt-get install openssh-client
  - sudo apt-get install openssh-server
  - ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
  - cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


script:
  # Build Mahout
  - mvn clean package $PROFILES $STANDARD_BUILD_OPTS -DskipTests
  # Start Spark
  - echo $SPARK_BIN
  - wget $SPARK_BIN
  - tar -xzf *tgz
  - spark*/sbin/start-all.sh
  # Run Tests with Master at spark://localhost:7077
  - mvn test -pl $TEST_MODULES $PROFILES -Dtest.spark.master=spark://localhost:7077
