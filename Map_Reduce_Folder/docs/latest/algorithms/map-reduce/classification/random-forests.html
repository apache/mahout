<!DOCTYPE html>
<html lang=" en ">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    (Deprecated)  Random Forests
    
  </title>

  <meta name="description" content="Distributed Linear Algebra">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/github-markdown.css">

  <!-- Font Awesome -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,700,700i" rel="stylesheet">

  <link rel="canonical" href="http://mahout.apache.org//Map_Reduce_Folder/docs/latest/algorithms/map-reduce/classification/random-forests.html">
  <link rel="alternate" type="application/rss+xml" title="Apache Mahout" href="/feed.xml">

  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML">
    MathJax.Hub.Config({
      "HTML-CSS": {
        availableFonts: ["TeX"],
      },
      tex2jax: {
        inlineMath: [['$','$'],["\\(","\\)"]]},
      displayMath: [ ['$$','$$'], ['\[','\]'] ],
      TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "color.js"],
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      showProcessingMessages: false,
      messageStyle: "none",
      imageFont: null,
      "AssistiveMML": { disabled: true }
    });
  </script>
</head>


<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light navbar-mahout">

    <div class="container">

        <a class="navbar-brand" href="/">
            <img src="/assets/mahout-logo-blue.svg" alt="">
        </a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">

            <div class="navbar-nav ml-auto">

                <!-- Quick Start -->
                <li class="nav-item">
                    <a class="nav-link" href="/docs/latest" >Overview</a>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Key Concepts</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/latest/index.html">Mahout Overview</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Scala DSL</h6>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/in-core-reference.html">In-core Reference</a>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/out-of-core-reference.html">Out-of-core Reference</a>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/faq.html">Samsara FAQ</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Distributed Engine Bindings</h6>
                        <a class="dropdown-item"  href="/docs/latest/distributed/spark-bindings/">Spark Bindings</a>
                        <a class="dropdown-item"  href="/docs/latest/distributed/flink-bindings.html">Flink Bindings</a>
                        <a class="dropdown-item"  href="/docs/latest/distributed/flink-bindings.html">H20 Bindings</a>
                        <!--<div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Native Solvers</h6>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/viennacl.html">ViennaCL</a></li>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/viennacl-omp.html">ViennaCL-OMP</a></li>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/cuda.html">CUDA</a></li>-->
                    </div>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Tutorial</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Recommenders</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/cco-lastfm">CCO Example with Last.FM Data</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/intro-cooccurrence-spark">Introduction to Cooccurrence in Spark</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Mahout Samsara</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/play-with-shell.html">Playing with Samsara in Spark Shell</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/playing-with-samsara-flink-batch.html">Playing with Samsara in Flink Batch</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/classify-a-doc-from-the-shell.html">Text Classification (Shell)</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/spark-naive-bayes.html">Spark Naive Bayes</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Misc</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/getting-started-with-zeppelin">Mahout in Apache Zeppelin (Quickstart)</a>
<!--                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/mahout-in-zeppelin">Mahout in Apache Zeppelin (Roll your own)</a>-->
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/contributing-algos">How To Contribute a New Algorithm</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/how-to-build-an-app.html">How To Build An App</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Deprecated</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/map-reduce">MapReduce</a>
                    </div>
                </li>


                <!-- Algorithms (Samsara / MR) -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Algorithms</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/latest/algorithms/linear-algebra">Distributed Linear Algebra</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/preprocessors">Preprocessors</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/regression">Regression</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/clustering">Clustering</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/recommenders">Recommenders</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Deprecated</h6>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/map-reduce">MapReduce <i>(deprecated)</i></a>
                    </div>
                        <!--<a class="dropdown-item"  href="/docs/latest/algorithms/recommenders/recommender-overview.html">Reccomender Overview</a></li> Do we still need? seems like short version of next post-->
                        <!--
                        <a class="dropdown-item"  href="/docs/latest/algorithms/recommenders/intro-cooccurrence-spark.html">Intro to Coocurrence With Spark</a></li>
                        <li role="separator" class="divider"></li>
                        <li><span>&nbsp;&nbsp;<a href="/docs/latest/algorithms/map-reduce"><b>MapReduce</b> (deprecated)</a><span></li>


                     -->
                </li>

                <!-- Scala /docs -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">API /docs</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/0.13.0/api/docs/">0.13.0</a>
                    </div>
                </li>

                <!-- Apache -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Apache</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/how-it-works.html">Apache Software Foundation</a>
                        <a class="dropdown-item"  href="http://www.apache.org/licenses/">Apache License</a>
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/thanks.html">Thanks</a>
                    </div>
                </li>

            </ul>

                <!--<form class="navbar-form navbar-left">-->
                    <!--<div class="form-group">-->
                        <!--<input type="text" class="form-control" placeholder="Search">-->
                    <!--</div>-->
                    <!--<button type="submit" class="btn btn-default">Submit</button>-->
                <!--</form>-->
                <!--<ul class="nav navbar-nav navbar-right">-->
                    <!--<a class="dropdown-item"  href="http://github.com/apache/mahout">Github</a></li>-->



                <!--</ul>-->
        </div><!-- /.navbar-collapse -->
    </div>
</nav>


  <div class="container mt-5 pb-4">

  <div class="row">

    <div class="col-lg-8 markdown-body">
      <p><a name="RandomForests-HowtogrowaDecisionTree"></a></p>
<h3 id="how-to-grow-a-decision-tree">How to grow a Decision Tree</h3>

<p>source : [3](3.html)</p>

<p>LearnUnprunedTree(<em>X</em>,<em>Y</em>)</p>

<p>Input: <em>X</em> a matrix of <em>R</em> rows and <em>M</em> columns where <em>X{</em>}{<em>}{~}ij{~}</em> =
the value of the <em>j</em>‘th attribute in the <em>i</em>‘th input datapoint. Each
column consists of either all real values or all categorical values.
Input: <em>Y</em> a vector of <em>R</em> elements, where <em>Y{</em>}{<em>}{~}i{~}</em> = the output
class of the <em>i</em>‘th datapoint. The <em>Y{</em>}{<em>}{~}i{~}</em> values are categorical.
Output: An Unpruned decision tree</p>

<p>If all records in <em>X</em> have identical values in all their attributes (this
includes the case where <em>R&lt;2</em>), return a Leaf Node predicting the majority
output, breaking ties randomly. This case also includes
If all values in <em>Y</em> are the same, return a Leaf Node predicting this value
as the output
Else
    select <em>m</em> variables at random out of the <em>M</em> variables
    For <em>j</em> = 1 .. <em>m</em>
        If <em>j</em>‘th attribute is
categorical
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG(<em>Y</em>|<em>X{</em>}{<em>}{~}j{~}</em>) (see Information
Gain)            
        Else (<em>j</em>‘th attribute is
real-valued)
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG<em>(</em>Y<em>|</em>X{<em>}{</em>}{~}j{~}<em>) (see Information Gain)
    Let *j*</em> = argmax{~}j~ <em>IG{</em>}{<em>}{~}j{~}</em> (this is the
splitting attribute we’ll use)
    If <em>j*</em> is categorical then
        For each value <em>v</em> of the <em>j</em>‘th
attribute
            Let
<em>X{</em>}{<em>}{^}v{^}</em> = subset of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> = <em>v</em>.
Let <em>Y{</em>}{<em>}{^}v{^}</em> = corresponding subset of <em>Y</em>
            Let <em>Child{</em>}{<em>}{^}v{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}v{^}</em>,<em>Y{</em>}{<em>}{^}v{^}</em>)
        Return a decision tree node,
splitting on <em>j</em>‘th attribute. The number of children equals the number of
values of the <em>j</em>‘th attribute, and the <em>v</em>‘th child is
<em>Child{</em>}{<em>}{^}v{^}</em>
    Else <em>j*</em> is real-valued and let <em>t</em> be the best split
threshold
        Let <em>X{</em>}{<em>}{^}LO{^}</em> = subset
of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&lt;= t</em>. Let <em>Y{</em>}{<em>}{^}LO{^}</em> =
corresponding subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}LO{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}LO{^}</em>,<em>Y{</em>}{<em>}{^}LO{^}</em>)
        Let <em>X{</em>}{<em>}{^}HI{^}</em> = subset of rows of <em>X</em>
in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&gt; t</em>. Let <em>Y{</em>}{<em>}{^}HI{^}</em> = corresponding
subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}HI{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}HI{^}</em>,<em>Y{</em>}{<em>}{^}HI{^}</em>)
        Return a decision tree node, splitting on
<em>j</em>‘th attribute. It has two children corresponding to whether the <em>j</em>‘th
attribute is above or below the given threshold.</p>

<p><em>Note</em>: There are alternatives to Information Gain for splitting nodes
 </p>

<p><a name="RandomForests-Informationgain"></a></p>
<h3 id="information-gain">Information gain</h3>

<p>source : [3](3.html)</p>
<ol>
  <li>h4. nominal attributes</li>
</ol>

<p>suppose X can have one of m values V{~}1~,V{~}2~,…,V{~}m~
P(X=V{~}1~)=p{~}1~, P(X=V{~}2~)=p{~}2~,…,P(X=V{~}m~)=p{~}m~
 
H(X)= -sum{~}j=1{~}{^}m^ p{~}j~ log{~}2~ p{~}j~ (The entropy of X)
H(Y|X=v) = the entropy of Y among only those records in which X has value
v
H(Y|X) = sum{~}j~ p{~}j~ H(Y|X=v{~}j~)
IG(Y|X) = H(Y) - H(Y|X)</p>
<ol>
  <li>h4. real-valued attributes</li>
</ol>

<p>suppose X is real valued
define IG(Y|X:t) as H(Y) - H(Y|X:t)
define H(Y|X:t) = H(Y|X&lt;t) P(X&lt;t) + H(Y|X&gt;=t) P(X&gt;=t)
define IG*(Y|X) = max{~}t~ IG(Y|X:t)</p>

<p><a name="RandomForests-HowtogrowaRandomForest"></a></p>
<h3 id="how-to-grow-a-random-forest">How to grow a Random Forest</h3>

<p>source : [1](1.html)</p>

<p>Each tree is grown as follows:</p>
<ol>
  <li>if the number of cases in the training set is <em>N</em>, sample <em>N</em> cases at
random -but with replacement, from the original data. This sample will be
the training set for the growing tree.</li>
  <li>if there are <em>M</em> input variables, a number <em>m « M</em> is specified such
that at each node, <em>m</em> variables are selected at random out of the <em>M</em> and
the best split on these <em>m</em> is used to split the node. The value of <em>m</em> is
held constant during the forest growing.</li>
  <li>each tree is grown to its large extent possible. There is no pruning.</li>
</ol>

<p><a name="RandomForests-RandomForestparameters"></a></p>
<h3 id="random-forest-parameters">Random Forest parameters</h3>

<p>source : [2](2.html)
Random Forests are easy to use, the only 2 parameters a user of the
technique has to determine are the number of trees to be used and the
number of variables (<em>m</em>) to be randomly selected from the available set of
variables.
Breinman’s recommendations are to pick a large number of trees, as well as
the square root of the number of variables for <em>m</em>.
 </p>

<p><a name="RandomForests-Howtopredictthelabelofacase"></a></p>
<h3 id="how-to-predict-the-label-of-a-case">How to predict the label of a case</h3>

<p>Classify(<em>node</em>,<em>V</em>)
    Input: <em>node</em> from the decision tree, if <em>node.attribute
= j</em> then the split is done on the <em>j</em>‘th attribute</p>

<p>    Input: <em>V</em> a vector of <em>M</em> columns where
<em>V{</em>}{<em>}{~}j{~}</em> = the value of the <em>j</em>‘th attribute.
    Output: label of <em>V</em></p>

<p>    If <em>node</em> is a Leaf then
            Return the value predicted
by <em>node</em></p>

<p>    Else
            Let <em>j =
node.attribute</em>
            If <em>j</em> is
categorical then
      
            
Let <em>v</em> = <em>V{</em>}{<em>}{~}j{~}</em>
      
            
Let <em>child{</em>}{<em>}{^}v{^}</em> = child node corresponding to the attribute’s
value <em>v</em>
              
     Return Classify(<em>child{</em>}{<em>}{^}v{^}</em>,<em>V</em>)</p>

<p>            Else <em>j</em> is
real-valued
      
            
Let <em>t = node.threshold</em> (split threshold)
              
     If Vj &lt; t then
                  
         Let <em>child{</em>}{<em>}{^}LO{^}</em> = child
node corresponding to (<em>&lt;t</em>)
                  
         Return
Classify(<em>child{</em>}{<em>}{^}LO{^}</em>,<em>V</em>)
      
            
Else
                  
         Let <em>child{</em>}{<em>}{^}HI{^}</em> =
child node corresponding to (<em>&gt;=t</em>)
               
            Return
Classify(<em>child{</em>}{<em>}{^}HI{^}</em>,<em>V</em>)
 </p>

<p><a name="RandomForests-Theoutofbag(oob)errorestimation"></a></p>
<h3 id="the-out-of-bag-oob-error-estimation">The out of bag (oob) error estimation</h3>

<p>source : [1](1.html)</p>

<p>in random forests, there is no need for cross-validation or a separate test
set to get an unbiased estimate of the test set error. It is estimated
internally, during the run, as follows:</p>
<ul>
  <li>each tree is constructed using a different bootstrap sample from the
original data. About one-third of the cases left of the bootstrap sample
and not used in the construction of the <em>kth</em> tree.</li>
  <li>put each case left out in the construction of the <em>kth</em> tree down the
<em>kth{</em>}tree to get a classification. In this way, a test set classification
is obtained for each case in about one-thrid of the trees. At the end of
the run, take <em>j</em> to be the class that got most of the the votes every time
case <em>n</em> was <em>oob</em>. The proportion of times that <em>j</em> is not equal to the
true class of <em>n</em> averaged over all cases is the <em>oob error estimate</em>. This
has proven to be unbiased in many tests.</li>
</ul>

<p><a name="RandomForests-OtherRFuses"></a></p>
<h3 id="other-rf-uses">Other RF uses</h3>

<p>source : [1](1.html)</p>
<ul>
  <li>variable importance</li>
  <li>gini importance</li>
  <li>proximities</li>
  <li>scaling</li>
  <li>prototypes</li>
  <li>missing values replacement for the training set</li>
  <li>missing values replacement for the test set</li>
  <li>detecting mislabeled cases</li>
  <li>detecting outliers</li>
  <li>detecting novelties</li>
  <li>unsupervised learning</li>
  <li>balancing prediction error
Please refer to [1](1.html)
 for a detailed description</li>
</ul>

<p><a name="RandomForests-References"></a></p>
<h3 id="references">References</h3>

<p>[1](1.html)
  Random Forests - Classification Description
        <a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a>
[2](2.html)
  B. Larivi�re &amp; D. Van Den Poel, 2004. “Predicting Customer Retention
and Profitability by Using Random Forests and Regression Forests
Techniques,”
        Working Papers of Faculty of
Economics and Business Administration, Ghent University, Belgium 04/282,
Ghent University,
        Faculty of Economics and
Business Administration.
        Available online : <a href="http://ideas.repec.org/p/rug/rugwps/04-282.html">http://ideas.repec.org/p/rug/rugwps/04-282.html</a>
[3](3.html)
  Decision Trees - Andrew W. Moore[4]
        http://www.cs.cmu.edu/~awm/tutorials[1](1.html)
[4](4.html)
  Information Gain - Andrew W. Moore
        <a href="http://www.cs.cmu.edu/~awm/tutorials">http://www.cs.cmu.edu/~awm/tutorials</a></p>

    </div>


  </div>

</div>


  <footer class="footer bg-light">
    <div class="container text-center small">
        Copyright &copy; 2014-2026 <a href="http://www.apache.org/">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
    </div>
</footer>


  <script src="/assets/vendor/jquery/jquery-slim.min.js"></script>
  <script src="/assets/vendor/popper/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap/js/bootstrap.min.js"></script>
  <script src="/assets/header.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</body>

</html>
