<!DOCTYPE html>
<html lang=" en ">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    Creating Vectors from Text
    
  </title>

  <meta name="description" content="Distributed Linear Algebra">

  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Font Awesome -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,700,700i" rel="stylesheet">

  <link rel="canonical" href="http://mahout.apache.org//Map_Reduce_Folder/basics/creating-vectors-from-text.html">
  <link rel="alternate" type="application/rss+xml" title="Apache Mahout" href="/feed.xml">

  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML">
    MathJax.Hub.Config({
      "HTML-CSS": {
        availableFonts: ["TeX"],
      },
      tex2jax: {
        inlineMath: [['$','$'],["\\(","\\)"]]},
      displayMath: [ ['$$','$$'], ['\[','\]'] ],
      TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "color.js"],
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      showProcessingMessages: false,
      messageStyle: "none",
      imageFont: null,
      "AssistiveMML": { disabled: true }
    });
  </script>
</head>

<!-- Matomo -->
<script>
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  _paq.push(["setDoNotTrack", true]);
  _paq.push(["disableCookies"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://analytics.apache.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '70']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<!-- End Matomo Code -->

<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light navbar-mahout">

    <div class="container">

        <a class="navbar-brand" href="/">
          <img src="/assets/mahout-logo-blue.svg" alt="">
        </a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">

            <ul class="navbar-nav ml-auto">

                <!-- About -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-about"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">About</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="https://www.apache.org/foundation/how-it-works.html">Overview of the Apache Software Foundation</a>
                        <a class="dropdown-item"
                           href="/about/distributed-matrix-math.html">Overview of Distributed Matrix Math</a>
                        <a class="dropdown-item"
                           href="/about/how-to-contribute.html">How to Contribute</a>
                    </div>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-qumat"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Qumat</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/quantum-computing-primer">Quantum Computing Primer</a>
<!--                        TODO: Add More QuMat stuff here or refactor the whole thing-->
                    </div>
                </li>
                <!-- Documentation -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-docs"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Documentation</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/papers.html">Papers</a>
                        <a class="dropdown-item"
                           href="/documentation/users">User Guide</a>
                        <a class="dropdown-item"
                           href="/documentation/developers">Developer Guide</a>
                        <a class="dropdown-item"
                           href="/docs/0.13.0/api/docs/">API Reference</a>
                        <a class="dropdown-item"
                           href="/documentation/tutorials">Tutorials and Examples</a>
                    </div>
                </li>

                <!-- Download -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-download"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Download</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/download/downloads.html">Latest Release</a>
                        <a class="dropdown-item"
                           href="https://github.com/apache/mahout/">Github Repository</a>
                    </div>
                </li>

                <!-- Community -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-community"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Community</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">

                        <a class="dropdown-item"
                           href="/community/">Overview</a>
                        <a class="dropdown-item"
                           href="/community/who-we-are.html">Who We Are</a>
                        <a class="dropdown-item"
                           href="/community/mailing-lists.html">Mailing Lists</a>
                        <a class="dropdown-item"
                           href="https://issues.apache.org/jira/browse/MAHOUT">Issue Tracker</a>
                        <a class="dropdown-item"
                           href="/documentation/developers/">Developer Documentation</a>
                        <a class="dropdown-item"
                           href="/community/coc.html">Code of Conduct</a>
                    </div>
                </li>

                <!-- News and Events -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="/news-and-events/news.html" id="navbarDropdownMenuLink-news-events"
                       aria-haspopup="true"
                       aria-expanded="false">Latest Project News</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/news-and-events/news.html">Latest Project News</a>
                    </div>
                </li>


                <!-- GitHub -->
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/apache/mahout"><i class="fa fa-github"></i></a>
                </li>

            </ul>

            <!-- <form class="form-inline my-2 my-lg-0">
            <input class="form-control mr-sm-2" type="text" placeholder="Search" aria-label="Search">
            <button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>
        </form> -->

        </div>

    </div>

</nav>


  <h1 id="creating-vectors-from-text">Creating vectors from text</h1>
<p><a name="CreatingVectorsfromText-Introduction"></a></p>
<h1 id="introduction">Introduction</h1>

<p>For clustering and classifying documents it is usually necessary to convert the raw text
into vectors that can then be consumed by the clustering <a href="algorithms.html">Algorithms</a>.  These approaches are described below.</p>

<p><a name="CreatingVectorsfromText-FromLucene"></a></p>
<h1 id="from-lucene">From Lucene</h1>

<p><em>NOTE: Your Lucene index must be created with the same version of Lucene
used in Mahout.  As of Mahout 0.9 this is Lucene 4.6.1. If these versions dont match you will likely get “Exception in thread “main”
org.apache.lucene.index.CorruptIndexException: Unknown format version: -11”
as an error.</em></p>

<p>Mahout has utilities that allow one to easily produce Mahout Vector
representations from a Lucene (and Solr, since they are they same) index.</p>

<p>For this, we assume you know how to build a Lucene/Solr index.	For those
who don’t, it is probably easiest to get up and running using <a href="http://lucene.apache.org/solr">Solr</a>
 as it can ingest things like PDFs, XML, Office, etc. and create a Lucene
index.	For those wanting to use just Lucene, see the <a href="http://lucene.apache.org/core">Lucene website</a>
 or check out <em>Lucene In Action</em> by Erik Hatcher, Otis Gospodnetic and Mike
McCandless.</p>

<p>To get started, make sure you get a fresh copy of Mahout from <a href="/documentation/developers/buildingmahout.html">GitHub</a>
 and are comfortable building it. It defines interfaces and implementations
for efficiently iterating over a data source (it only supports Lucene
currently, but should be extensible to databases, Solr, etc.) and produces
a Mahout Vector file and term dictionary which can then be used for
clustering.   The main code for driving this is the driver program located
in the org.apache.mahout.utils.vectors package.  The driver program offers
several input options, which can be displayed by specifying the –help
option.  Examples of running the driver are included below:</p>

<p><a name="CreatingVectorsfromText-GeneratinganoutputfilefromaLuceneIndex"></a></p>
<h4 id="generating-an-output-file-from-a-lucene-index">Generating an output file from a Lucene Index</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout lucene.vector
    --dir (-d) dir                     The Lucene directory
    --idField idField                  The field in the index
                                           containing the index.  If
                                           null, then the Lucene
                                           internal doc id is used
                                           which is prone to error
                                           if the underlying index
                                           changes
    --output (-o) output               The output file
    --delimiter (-l) delimiter         The delimiter for
                                           outputting the dictionary
    --help (-h)                        Print out help
    --field (-f) field                 The field in the index
    --max (-m) max                         The maximum number of
                                           vectors to output.  If
                                           not specified, then it
                                           will loop over all docs
    --dictOut (-t) dictOut             The output of the
                                           dictionary
    --seqDictOut (-st) seqDictOut      The output of the
                                           dictionary as sequence
                                           file
    --norm (-n) norm                   The norm to use,
                                           expressed as either a
                                           double or "INF" if you
                                           want to use the Infinite
                                           norm.  Must be greater or
                                           equal to 0.  The default
                                           is not to normalize
    --maxDFPercent (-x) maxDFPercent   The max percentage of
                                           docs for the DF.  Can be
                                           used to remove really
                                           high frequency terms.
                                           Expressed as an integer
                                           between 0 and 100.
                                           Default is 99.
    --weight (-w) weight               The kind of weight to
                                           use. Currently TF or
                                           TFIDF
    --minDF (-md) minDF                The minimum document
                                           frequency.  Default is 1
    --maxPercentErrorDocs (-err) mErr  The max percentage of
                                           docs that can have a null
                                           term vector. These are
                                           noise document and can
                                           occur if the analyzer
                                           used strips out all terms
                                           in the target field. This
                                           percentage is expressed
                                           as a value between 0 and
                                           1. The default is 0.
</code></pre></div></div>

<h4 id="example-create-50-vectors-from-an-index">Example: Create 50 Vectors from an Index</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout lucene.vector
    --dir $WORK_DIR/wikipedia/solr/data/index
    --field body
    --dictOut $WORK_DIR/solr/wikipedia/dict.txt
    --output $WORK_DIR/solr/wikipedia/out.txt
    --max 50
</code></pre></div></div>

<p>This uses the index specified by –dir and the body field in it and writes
out the info to the output dir and the dictionary to dict.txt.	It only
outputs 50 vectors.  If you don’t specify –max, then all the documents in
the index are output.</p>

<p><a name="CreatingVectorsfromText-50VectorsFromLuceneL2Norm"></a></p>
<h4 id="example-creating-50-normalized-vectors-from-a-lucene-index-using-the-l_2-norm">Example: Creating 50 Normalized Vectors from a Lucene Index using the <a href="http://en.wikipedia.org/wiki/Lp_space">L_2 Norm</a></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout lucene.vector
    --dir $WORK_DIR/wikipedia/solr/data/index
    --field body
    --dictOut $WORK_DIR/solr/wikipedia/dict.txt
    --output $WORK_DIR/solr/wikipedia/out.txt
    --max 50
    --norm 2
</code></pre></div></div>

<p><a name="CreatingVectorsfromText-FromDirectoryofTextdocuments"></a></p>
<h2 id="from-a-directory-of-text-documents">From A Directory of Text documents</h2>
<p>Mahout has utilities to generate Vectors from a directory of text
documents. Before creating the vectors, you need to convert the documents
to SequenceFile format. SequenceFile is a hadoop class which allows us to
write arbitary (key, value) pairs into it. The DocumentVectorizer requires the
key to be a Text with a unique document id, and value to be the Text
content in UTF-8 format.</p>

<p>You may find <a href="http://tika.apache.org/">Tika</a> helpful in converting
binary documents to text.</p>

<p><a name="CreatingVectorsfromText-ConvertingdirectoryofdocumentstoSequenceFileformat"></a></p>
<h4 id="converting-directory-of-documents-to-sequencefile-format">Converting directory of documents to SequenceFile format</h4>
<p>Mahout has a nifty utility which reads a directory path including its
sub-directories and creates the SequenceFile in a chunked manner for us.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout seqdirectory
    --input (-i) input                       Path to job input directory.
    --output (-o) output                     The directory pathname for
                                                 output.
    --overwrite (-ow)                        If present, overwrite the
                                                 output directory before
                                                 running job
    --method (-xm) method                    The execution method to use:
                                                 sequential or mapreduce.
                                                 Default is mapreduce
    --chunkSize (-chunk) chunkSize           The chunkSize in MegaBytes.
                                                 Defaults to 64
    --fileFilterClass (-filter) fFilterClass The name of the class to use
                                                 for file parsing. Default:
                                                 org.apache.mahout.text.PrefixAdditionFilter
    --keyPrefix (-prefix) keyPrefix          The prefix to be prepended to
                                                 the key
    --charset (-c) charset                   The name of the character
                                                 encoding of the input files.
                                                 Default to UTF-8 {accepts: cp1252|ascii...}
    --method (-xm) method                    The execution method to use:
                                                 sequential or mapreduce.
                                             Default is mapreduce
    --overwrite (-ow)                        If present, overwrite the
                                                 output directory before
                                                 running job
    --help (-h)                              Print out help
    --tempDir tempDir                        Intermediate output directory
    --startPhase startPhase                  First phase to run
    --endPhase endPhase                      Last phase to run
</code></pre></div></div>

<p>The output of seqDirectory will be a Sequence file &lt; Text, Text &gt; of all documents (/sub-directory-path/documentFileName, documentText).</p>

<p><a name="CreatingVectorsfromText-CreatingVectorsfromSequenceFile"></a></p>
<h4 id="creating-vectors-from-sequencefile">Creating Vectors from SequenceFile</h4>

<p>From the sequence file generated from the above step run the following to
generate vectors.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout seq2sparse
    --minSupport (-s) minSupport      (Optional) Minimum Support. Default
                                          Value: 2
    --analyzerName (-a) analyzerName  The class name of the analyzer
    --chunkSize (-chunk) chunkSize    The chunkSize in MegaBytes. Default
                                          Value: 100MB
    --output (-o) output              The directory pathname for output.
    --input (-i) input                Path to job input directory.
    --minDF (-md) minDF               The minimum document frequency.  Default
                                          is 1
    --maxDFSigma (-xs) maxDFSigma     What portion of the tf (tf-idf) vectors
                                          to be used, expressed in times the
                                          standard deviation (sigma) of the
                                          document frequencies of these vectors.
                                          Can be used to remove really high
                                          frequency terms. Expressed as a double
                                          value. Good value to be specified is 3.0.
                                          In case the value is less than 0 no
                                          vectors will be filtered out. Default is
                                          -1.0.  Overrides maxDFPercent
    --maxDFPercent (-x) maxDFPercent  The max percentage of docs for the DF.
                                          Can be used to remove really high
                                          frequency terms. Expressed as an integer
                                          between 0 and 100. Default is 99.  If
                                          maxDFSigma is also set, it will override
                                          this value.
    --weight (-wt) weight             The kind of weight to use. Currently TF
                                          or TFIDF. Default: TFIDF
    --norm (-n) norm                  The norm to use, expressed as either a
                                          float or "INF" if you want to use the
                                          Infinite norm.  Must be greater or equal
                                          to 0.  The default is not to normalize
    --minLLR (-ml) minLLR             (Optional)The minimum Log Likelihood
                                          Ratio(Float)  Default is 1.0
    --numReducers (-nr) numReducers   (Optional) Number of reduce tasks.
                                          Default Value: 1
    --maxNGramSize (-ng) ngramSize    (Optional) The maximum size of ngrams to
                                          create (2 = bigrams, 3 = trigrams, etc)
                                          Default Value:1
    --overwrite (-ow)                 If set, overwrite the output directory
    --help (-h)                           Print out help
    --sequentialAccessVector (-seq)   (Optional) Whether output vectors should
                                          be SequentialAccessVectors. Default is false;
                                          true required for running some algorithms
                                          (LDA,Lanczos)
    --namedVector (-nv)               (Optional) Whether output vectors should
                                          be NamedVectors. If set true else false
    --logNormalize (-lnorm)           (Optional) Whether output vectors should
                                          be logNormalize. If set true else false
</code></pre></div></div>

<p>This will create SequenceFiles of tokenized documents &lt; Text, StringTuple &gt;  (docID, tokenizedDoc) and vectorized documents &lt; Text, VectorWritable &gt; (docID, TF-IDF Vector).</p>

<p>As well, seq2sparse will create SequenceFiles for: a dictionary (wordIndex, word), a word frequency count (wordIndex, count) and a document frequency count (wordIndex, DFCount) in the output directory.</p>

<p>The –minSupport option is the min frequency for the word to be considered as a feature; –minDF is the min number of documents the word needs to be in; –maxDFPercent is the max value of the expression (document frequency of a word/total number of document) to be considered as good feature to be in the document. These options are helpful in removing high frequency features like stop words.</p>

<p>The vectorized documents can then be used as input to many of Mahout’s classification and clustering algorithms.</p>

<h4 id="example-creating-normalized-tf-idf-vectors-from-a-directory-of-text-documents-using-trigrams-and-the-l_2-norm">Example: Creating Normalized <a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> Vectors from a directory of text documents using <a href="http://en.wikipedia.org/wiki/N-gram">trigrams</a> and the <a href="http://en.wikipedia.org/wiki/Lp_space">L_2 Norm</a></h4>
<p>Create sequence files from the directory of text documents:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout seqdirectory
    -i $WORK_DIR/reuters
    -o $WORK_DIR/reuters-seqdir
    -c UTF-8
    -chunk 64
    -xm sequential
</code></pre></div></div>

<p>Vectorize the documents using trigrams, L_2 length normalization and a maximum document frequency cutoff of 85%.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$MAHOUT_HOME/bin/mahout seq2sparse
    -i $WORK_DIR/reuters-out-seqdir/
    -o $WORK_DIR/reuters-out-seqdir-sparse-kmeans
    --namedVec
    -wt tfidf
    -ng 3
    -n 2
    --maxDFPercent 85
</code></pre></div></div>

<p>The sequence file in the $WORK_DIR/reuters-out-seqdir-sparse-kmeans/tfidf-vectors directory can now be used as input to the Mahout <a href="http://mahout.apache.org/users/clustering/k-means-clustering.html">k-Means</a> clustering algorithm.</p>

<p><a name="CreatingVectorsfromText-Background"></a></p>
<h2 id="background">Background</h2>

<ul>
  <li><a href="http://markmail.org/thread/l5zi3yk446goll3o">Discussion on centroid calculations with sparse vectors</a></li>
</ul>

<p><a name="CreatingVectorsfromText-ConvertingexistingvectorstoMahout'sformat"></a></p>
<h2 id="converting-existing-vectors-to-mahouts-format">Converting existing vectors to Mahout’s format</h2>

<p>If you are in the happy position to already own a document (as in: texts,
images or whatever item you wish to treat) processing pipeline, the
question arises of how to convert the vectors into the Mahout vector
format. Probably the easiest way to go would be to implement your own
Iterable<Vector> (called VectorIterable in the example below) and then
reuse the existing VectorWriter classes:</Vector></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>VectorWriter vectorWriter = SequenceFile.createWriter(filesystem,
                                                      configuration,
                                                      outfile,
                                                      LongWritable.class,
                                                      SparseVector.class);

long numDocs = vectorWriter.write(new VectorIterable(), Long.MAX_VALUE);
</code></pre></div></div>

  <footer class="footer bg-light">
    <div class="container text-center small">
        Copyright &copy; 2014-2026 <a href="http://www.apache.org/">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
    </div>
</footer>

  <script src="/assets/vendor/jquery/jquery-slim.min.js"></script>
  <script src="/assets/vendor/popper/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap/js/bootstrap.min.js"></script>
  <script src="/assets/header.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</body>
</html>
