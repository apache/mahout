<!DOCTYPE html>
<html lang=" en ">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    Text Classification Example
    
  </title>

  <meta name="description" content="Distributed Linear Algebra">

  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Font Awesome -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,700,700i" rel="stylesheet">

  <link rel="canonical" href="http://mahout.apache.org//documentation/tutorials/samsara/classify-a-doc-from-the-shell.html">
  <link rel="alternate" type="application/rss+xml" title="Apache Mahout" href="/feed.xml">


</head>


<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light navbar-mahout">

    <div class="container">

        <a class="navbar-brand" href="/">
            <img src="/assets/mahout-logo-blue.svg" alt="">
        </a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">

            <div class="navbar-nav ml-auto">

                <!-- Quick Start -->
                <li class="nav-item">
                    <a class="nav-link" href="/docs/latest" >Overview</a>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Key Concepts</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/latest/index.html">Mahout Overview</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Scala DSL</h6>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/in-core-reference.html">In-core Reference</a>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/out-of-core-reference.html">Out-of-core Reference</a>
                        <a class="dropdown-item"  href="/docs/latest/mahout-samsara/faq.html">Samsara FAQ</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Distributed Engine Bindings</h6>
                        <a class="dropdown-item"  href="/docs/latest/distributed/spark-bindings/">Spark Bindings</a>
                        <a class="dropdown-item"  href="/docs/latest/distributed/flink-bindings.html">Flink Bindings</a>
                        <a class="dropdown-item"  href="/docs/latest/distributed/flink-bindings.html">H20 Bindings</a>
                        <!--<div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Native Solvers</h6>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/viennacl.html">ViennaCL</a></li>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/viennacl-omp.html">ViennaCL-OMP</a></li>
                        <a class="dropdown-item"  href="/docs/latest/native-solvers/cuda.html">CUDA</a></li>-->
                    </div>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Tutorial</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Recommenders</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/cco-lastfm">CCO Example with Last.FM Data</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/intro-cooccurrence-spark">Introduction to Cooccurrence in Spark</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Mahout Samsara</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/play-with-shell.html">Playing with Samsara in Spark Shell</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/playing-with-samsara-flink-batch.html">Playing with Samsara in Flink Batch</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/classify-a-doc-from-the-shell.html">Text Classification (Shell)</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/samsara/spark-naive-bayes.html">Spark Naive Bayes</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Misc</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/getting-started-with-zeppelin">Mahout in Apache Zeppelin (Quickstart)</a>
<!--                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/mahout-in-zeppelin">Mahout in Apache Zeppelin (Roll your own)</a>-->
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/contributing-algos">How To Contribute a New Algorithm</a>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/misc/how-to-build-an-app.html">How To Build An App</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Deprecated</h6>
                        <a class="dropdown-item"  href="/docs/latest/tutorials/map-reduce">MapReduce</a>
                    </div>
                </li>


                <!-- Algorithms (Samsara / MR) -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Algorithms</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/latest/algorithms/linear-algebra">Distributed Linear Algebra</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/preprocessors">Preprocessors</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/regression">Regression</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/clustering">Clustering</a>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/recommenders">Recommenders</a>
                        <div class="dropdown-divider"></div>
                        <h6 class="dropdown-header">Deprecated</h6>
                        <a class="dropdown-item"  href="/docs/latest/algorithms/map-reduce">MapReduce <i>(deprecated)</i></a>
                    </div>
                        <!--<a class="dropdown-item"  href="/docs/latest/algorithms/recommenders/recommender-overview.html">Reccomender Overview</a></li> Do we still need? seems like short version of next post-->
                        <!--
                        <a class="dropdown-item"  href="/docs/latest/algorithms/recommenders/intro-cooccurrence-spark.html">Intro to Coocurrence With Spark</a></li>
                        <li role="separator" class="divider"></li>
                        <li><span>&nbsp;&nbsp;<a href="/docs/latest/algorithms/map-reduce"><b>MapReduce</b> (deprecated)</a><span></li>


                     -->
                </li>

                <!-- Scala /docs -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">API /docs</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="/docs/0.13.0/api/docs/">0.13.0</a>
                    </div>
                </li>

                <!-- Apache -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Apache</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/how-it-works.html">Apache Software Foundation</a>
                        <a class="dropdown-item"  href="http://www.apache.org/licenses/">Apache License</a>
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
                        <a class="dropdown-item"  href="http://www.apache.org/foundation/thanks.html">Thanks</a>
                    </div>
                </li>

            </ul>

                <!--<form class="navbar-form navbar-left">-->
                    <!--<div class="form-group">-->
                        <!--<input type="text" class="form-control" placeholder="Search">-->
                    <!--</div>-->
                    <!--<button type="submit" class="btn btn-default">Submit</button>-->
                <!--</form>-->
                <!--<ul class="nav navbar-nav navbar-right">-->
                    <!--<a class="dropdown-item"  href="http://github.com/apache/mahout">Github</a></li>-->



                <!--</ul>-->
        </div><!-- /.navbar-collapse -->
    </div>
</nav>


  <div class="container mt-5 pb-4">

  <div class="row">

    <div class="col-lg-8">
      <h1 id="building-a-text-classifier-in-mahouts-spark-shell">Building a text classifier in Mahout’s Spark Shell</h1>

<p>This tutorial will take you through the steps used to train a Multinomial Naive Bayes model and create a text classifier based on that model using the <code class="language-plaintext highlighter-rouge">mahout spark-shell</code>.</p>

<h2 id="prerequisites">Prerequisites</h2>
<p>This tutorial assumes that you have your Spark environment variables set for the <code class="language-plaintext highlighter-rouge">mahout spark-shell</code> see: <a href="http://mahout.apache.org/users/sparkbindings/play-with-shell.html">Playing with Mahout’s Shell</a>.  As well we assume that Mahout is running in cluster mode (i.e. with the <code class="language-plaintext highlighter-rouge">MAHOUT_LOCAL</code> environment variable <strong>unset</strong>) as we’ll be reading and writing to HDFS.</p>

<h2 id="downloading-and-vectorizing-the-wikipedia-dataset">Downloading and Vectorizing the Wikipedia dataset</h2>
<p><em>As of Mahout v. 0.10.0, we are still reliant on the MapReduce versions of <code class="language-plaintext highlighter-rouge">mahout seqwiki</code> and <code class="language-plaintext highlighter-rouge">mahout seq2sparse</code> to extract and vectorize our text.  A</em> <a href="https://issues.apache.org/jira/browse/MAHOUT-1663"><em>Spark implementation of seq2sparse</em></a> <em>is in the works for Mahout v. 0.11.</em> However, to download the Wikipedia dataset, extract the bodies of the documentation, label each document and vectorize the text into TF-IDF vectors, we can simpmly run the <a href="https://github.com/apache/mahout/blob/master/examples/bin/classify-wikipedia.sh">wikipedia-classifier.sh</a> example.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Please select a number to choose the corresponding task to run
1. CBayes (may require increased heap space on yarn)
2. BinaryCBayes
3. clean -- cleans up the work area in /tmp/mahout-work-wiki
Enter your choice :
</code></pre></div></div>

<p>Enter (2). This will download a large recent XML dump of the Wikipedia database, into a <code class="language-plaintext highlighter-rouge">/tmp/mahout-work-wiki</code> directory, unzip it and  place it into HDFS.  It will run a <a href="http://mahout.apache.org/users/classification/wikipedia-classifier-example.html">MapReduce job to parse the wikipedia set</a>, extracting and labeling only pages with category tags for [United States] and [United Kingdom] (~11600 documents). It will then run <code class="language-plaintext highlighter-rouge">mahout seq2sparse</code> to convert the documents into TF-IDF vectors.  The script will also a build and test a <a href="http://mahout.apache.org/users/classification/bayesian.html">Naive Bayes model using MapReduce</a>.  When it is completed, you should see a confusion matrix on your screen.  For this tutorial, we will ignore the MapReduce model, and build a new model using Spark based on the vectorized text output by <code class="language-plaintext highlighter-rouge">seq2sparse</code>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>Launch the <code class="language-plaintext highlighter-rouge">mahout spark-shell</code>.  There is an example script: <code class="language-plaintext highlighter-rouge">spark-document-classifier.mscala</code> (.mscala denotes a Mahout-Scala script which can be run similarly to an R script).   We will be walking through this script for this tutorial but if you wanted to simply run the script, you could just issue the command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mahout&gt; :load /path/to/mahout/examples/bin/spark-document-classifier.mscala
</code></pre></div></div>

<p>For now, lets take the script apart piece by piece.  You can cut and paste the following code blocks into the <code class="language-plaintext highlighter-rouge">mahout spark-shell</code>.</p>

<h2 id="imports">Imports</h2>

<p>Our Mahout Naive Bayes imports:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.mahout.classifier.naivebayes._
import org.apache.mahout.classifier.stats._
import org.apache.mahout.nlp.tfidf._
</code></pre></div></div>

<p>Hadoop imports needed to read our dictionary:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.hadoop.io.Text
import org.apache.hadoop.io.IntWritable
import org.apache.hadoop.io.LongWritable
</code></pre></div></div>

<h2 id="read-in-our-full-set-from-hdfs-as-vectorized-by-seq2sparse-in-classify-wikipediash">Read in our full set from HDFS as vectorized by seq2sparse in classify-wikipedia.sh</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val pathToData = "/tmp/mahout-work-wiki/"
val fullData = drmDfsRead(pathToData + "wikipediaVecs/tfidf-vectors")
</code></pre></div></div>

<h2 id="extract-the-category-of-each-observation-and-aggregate-those-observations-by-category">Extract the category of each observation and aggregate those observations by category</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val (labelIndex, aggregatedObservations) = SparkNaiveBayes.extractLabelsAndAggregateObservations(
                                                             fullData)
</code></pre></div></div>

<h2 id="build-a-muitinomial-naive-bayes-model-and-self-test-on-the-training-set">Build a Muitinomial Naive Bayes model and self test on the training set</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val model = SparkNaiveBayes.train(aggregatedObservations, labelIndex, false)
val resAnalyzer = SparkNaiveBayes.test(model, fullData, false)
println(resAnalyzer)
</code></pre></div></div>

<p>printing the <code class="language-plaintext highlighter-rouge">ResultAnalyzer</code> will display the confusion matrix.</p>

<h2 id="read-in-the-dictionary-and-document-frequency-count-from-hdfs">Read in the dictionary and document frequency count from HDFS</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val dictionary = sdc.sequenceFile(pathToData + "wikipediaVecs/dictionary.file-0",
                                  classOf[Text],
                                  classOf[IntWritable])
val documentFrequencyCount = sdc.sequenceFile(pathToData + "wikipediaVecs/df-count",
                                              classOf[IntWritable],
                                              classOf[LongWritable])

// setup the dictionary and document frequency count as maps
val dictionaryRDD = dictionary.map { 
                                case (wKey, wVal) =&gt; wKey.asInstanceOf[Text]
                                                         .toString() -&gt; wVal.get() 
                                   }
                                   
val documentFrequencyCountRDD = documentFrequencyCount.map {
                                        case (wKey, wVal) =&gt; wKey.asInstanceOf[IntWritable]
                                                                 .get() -&gt; wVal.get() 
                                                           }

val dictionaryMap = dictionaryRDD.collect.map(x =&gt; x._1.toString -&gt; x._2.toInt).toMap
val dfCountMap = documentFrequencyCountRDD.collect.map(x =&gt; x._1.toInt -&gt; x._2.toLong).toMap
</code></pre></div></div>

<h2 id="define-a-function-to-tokenize-and-vectorize-new-text-using-our-current-dictionary">Define a function to tokenize and vectorize new text using our current dictionary</h2>

<p>For this simple example, our function <code class="language-plaintext highlighter-rouge">vectorizeDocument(...)</code> will tokenize a new document into unigrams using native Java String methods and vectorize using our dictionary and document frequencies. You could also use a <a href="https://lucene.apache.org/core/">Lucene</a> analyzer for bigrams, trigrams, etc., and integrate Apache <a href="https://tika.apache.org/">Tika</a> to extract text from different document types (PDF, PPT, XLS, etc.).  Here, however we will keep it simple, stripping and tokenizing our text using regexs and native String methods.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def vectorizeDocument(document: String,
                        dictionaryMap: Map[String,Int],
                        dfMap: Map[Int,Long]): Vector = {
    val wordCounts = document.replaceAll("[^\\p{L}\\p{Nd}]+", " ")
                                .toLowerCase
                                .split(" ")
                                .groupBy(identity)
                                .mapValues(_.length)         
    val vec = new RandomAccessSparseVector(dictionaryMap.size)
    val totalDFSize = dfMap(-1)
    val docSize = wordCounts.size
    for (word &lt;- wordCounts) {
        val term = word._1
        if (dictionaryMap.contains(term)) {
            val tfidf: TermWeight = new TFIDF()
            val termFreq = word._2
            val dictIndex = dictionaryMap(term)
            val docFreq = dfCountMap(dictIndex)
            val currentTfIdf = tfidf.calculate(termFreq,
                                               docFreq.toInt,
                                               docSize,
                                               totalDFSize.toInt)
            vec.setQuick(dictIndex, currentTfIdf)
        }
    }
    vec
}
</code></pre></div></div>

<h2 id="setup-our-classifier">Setup our classifier</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val labelMap = model.labelIndex
val numLabels = model.numLabels
val reverseLabelMap = labelMap.map(x =&gt; x._2 -&gt; x._1)

// instantiate the correct type of classifier
val classifier = model.isComplementary match {
    case true =&gt; new ComplementaryNBClassifier(model)
    case _ =&gt; new StandardNBClassifier(model)
}
</code></pre></div></div>

<h2 id="define-an-argmax-function">Define an argmax function</h2>

<p>The label with the highest score wins the classification for a given document.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def argmax(v: Vector): (Int, Double) = {
    var bestIdx: Int = Integer.MIN_VALUE
    var bestScore: Double = Integer.MIN_VALUE.asInstanceOf[Int].toDouble
    for(i &lt;- 0 until v.size) {
        if(v(i) &gt; bestScore){
            bestScore = v(i)
            bestIdx = i
        }
    }
    (bestIdx, bestScore)
}
</code></pre></div></div>

<h2 id="define-our-tf-idf-vector-classifier">Define our TF(-IDF) vector classifier</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def classifyDocument(clvec: Vector) : String = {
    val cvec = classifier.classifyFull(clvec)
    val (bestIdx, bestScore) = argmax(cvec)
    reverseLabelMap(bestIdx)
}
</code></pre></div></div>

<h2 id="two-sample-news-articles-united-states-football-and-united-kingdom-football">Two sample news articles: United States Football and United Kingdom Football</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// A random United States football article
// http://www.reuters.com/article/2015/01/28/us-nfl-superbowl-security-idUSKBN0L12JR20150128
val UStextToClassify = new String("(Reuters) - Super Bowl security officials acknowledge" +
    " the NFL championship game represents a high profile target on a world stage but are" +
    " unaware of any specific credible threats against Sunday's showcase. In advance of" +
    " one of the world's biggest single day sporting events, Homeland Security Secretary" +
    " Jeh Johnson was in Glendale on Wednesday to review security preparations and tour" +
    " University of Phoenix Stadium where the Seattle Seahawks and New England Patriots" +
    " will battle. Deadly shootings in Paris and arrest of suspects in Belgium, Greece and" +
    " Germany heightened fears of more attacks around the world and social media accounts" +
    " linked to Middle East militant groups have carried a number of threats to attack" +
    " high-profile U.S. events. There is no specific credible threat, said Johnson, who" + 
    " has appointed a federal coordination team to work with local, state and federal" +
    " agencies to ensure safety of fans, players and other workers associated with the" + 
    " Super Bowl. I'm confident we will have a safe and secure and successful event." +
    " Sunday's game has been given a Special Event Assessment Rating (SEAR) 1 rating, the" +
    " same as in previous years, except for the year after the Sept. 11, 2001 attacks, when" +
    " a higher level was declared. But security will be tight and visible around Super" +
    " Bowl-related events as well as during the game itself. All fans will pass through" +
    " metal detectors and pat downs. Over 4,000 private security personnel will be deployed" +
    " and the almost 3,000 member Phoenix police force will be on Super Bowl duty. Nuclear" +
    " device sniffing teams will be deployed and a network of Bio-Watch detectors will be" +
    " set up to provide a warning in the event of a biological attack. The Department of" +
    " Homeland Security (DHS) said in a press release it had held special cyber-security" +
    " and anti-sniper training sessions. A U.S. official said the Transportation Security" +
    " Administration, which is responsible for screening airline passengers, will add" +
    " screeners and checkpoint lanes at airports. Federal air marshals, behavior detection" +
    " officers and dog teams will help to secure transportation systems in the area. We" +
    " will be ramping it (security) up on Sunday, there is no doubt about that, said Federal"+
    " Coordinator Matthew Allen, the DHS point of contact for planning and support. I have" +
    " every confidence the public safety agencies that represented in the planning process" +
    " are going to have their best and brightest out there this weekend and we will have" +
    " a very safe Super Bowl.")

// A random United Kingdom football article
// http://www.reuters.com/article/2015/01/26/manchester-united-swissquote-idUSL6N0V52RZ20150126
val UKtextToClassify = new String("(Reuters) - Manchester United have signed a sponsorship" +
    " deal with online financial trading company Swissquote, expanding the commercial" +
    " partnerships that have helped to make the English club one of the richest teams in" +
    " world soccer. United did not give a value for the deal, the club's first in the sector," +
    " but said on Monday it was a multi-year agreement. The Premier League club, 20 times" +
    " English champions, claim to have 659 million followers around the globe, making the" +
    " United name attractive to major brands like Chevrolet cars and sportswear group Adidas." +
    " Swissquote said the global deal would allow it to use United's popularity in Asia to" +
    " help it meet its targets for expansion in China. Among benefits from the deal," +
    " Swissquote's clients will have a chance to meet United players and get behind the scenes" +
    " at the Old Trafford stadium. Swissquote is a Geneva-based online trading company that" +
    " allows retail investors to buy and sell foreign exchange, equities, bonds and other asset" +
    " classes. Like other retail FX brokers, Swissquote was left nursing losses on the Swiss" +
    " franc after Switzerland's central bank stunned markets this month by abandoning its cap" +
    " on the currency. The fallout from the abrupt move put rival and West Ham United shirt" +
    " sponsor Alpari UK into administration. Swissquote itself was forced to book a 25 million" +
    " Swiss francs ($28 million) provision for its clients who were left out of pocket" +
    " following the franc's surge. United's ability to grow revenues off the pitch has made" +
    " them the second richest club in the world behind Spain's Real Madrid, despite a" +
    " downturn in their playing fortunes. United Managing Director Richard Arnold said" +
    " there was still lots of scope for United to develop sponsorships in other areas of" +
    " business. The last quoted statistics that we had showed that of the top 25 sponsorship" +
    " categories, we were only active in 15 of those, Arnold told Reuters. I think there is a" +
    " huge potential still for the club, and the other thing we have seen is there is very" +
    " significant growth even within categories. United have endured a tricky transition" +
    " following the retirement of manager Alex Ferguson in 2013, finishing seventh in the" +
    " Premier League last season and missing out on a place in the lucrative Champions League." +
    " ($1 = 0.8910 Swiss francs) (Writing by Neil Maidment, additional reporting by Jemima" + 
    " Kelly; editing by Keith Weir)")
</code></pre></div></div>

<h2 id="vectorize-and-classify-our-documents">Vectorize and classify our documents</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val usVec = vectorizeDocument(UStextToClassify, dictionaryMap, dfCountMap)
val ukVec = vectorizeDocument(UKtextToClassify, dictionaryMap, dfCountMap)

println("Classifying the news article about superbowl security (united states)")
classifyDocument(usVec)

println("Classifying the news article about Manchester United (united kingdom)")
classifyDocument(ukVec)
</code></pre></div></div>

<h2 id="tie-everything-together-in-a-new-method-to-classify-text">Tie everything together in a new method to classify text</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def classifyText(txt: String): String = {
    val v = vectorizeDocument(txt, dictionaryMap, dfCountMap)
    classifyDocument(v)
}
</code></pre></div></div>

<h2 id="now-we-can-simply-call-our-classifytext-method-on-any-string">Now we can simply call our classifyText(…) method on any String</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>classifyText("Hello world from Queens")
classifyText("Hello world from London")
</code></pre></div></div>

<h2 id="model-persistance">Model persistance</h2>

<p>You can save the model to HDFS:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.dfsWrite("/path/to/model")
</code></pre></div></div>

<p>And retrieve it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val model =  NBModel.dfsRead("/path/to/model")
</code></pre></div></div>

<p>The trained model can now be embedded in an external application.</p>

    </div>


  </div>

</div>


  <footer class="footer bg-light">
    <div class="container text-center small">
        Copyright &copy; 2014-2024 <a href="http://www.apache.org/">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
    </div>
</footer>


  <script src="/assets/vendor/jquery/jquery-slim.min.js"></script>
  <script src="/assets/vendor/popper/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap/js/bootstrap.min.js"></script>
  <script src="/assets/header.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</body>

</html>
