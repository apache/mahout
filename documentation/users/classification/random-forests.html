<!DOCTYPE html>
<html lang=" en ">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    Random Forests
    
  </title>

  <meta name="description" content="Distributed Linear Algebra">

  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Font Awesome -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,700,700i" rel="stylesheet">

  <link rel="canonical" href="http://mahout.apache.org//documentation/users/classification/random-forests.html">
  <link rel="alternate" type="application/rss+xml" title="Apache Mahout" href="/feed.xml">


</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-98314020-1', 'auto');
  ga('send', 'pageview');
</script>

<body>

  <nav class="navbar navbar-expand-lg navbar-light bg-light navbar-mahout">

    <div class="container">

        <a class="navbar-brand" href="/">
          <img src="/assets/mahout-logo-blue.svg" alt="">
        </a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">

            <ul class="navbar-nav ml-auto">

                <!-- About -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-about"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">About</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="https://www.apache.org/foundation/how-it-works.html">Overview of the Apache Software Foundation</a>
                        <a class="dropdown-item"
                           href="/about/distributed-matrix-math.html">Overview of Distributed Matrix Math</a>
                        <a class="dropdown-item"
                           href="/about/how-to-contribute.html">How to Contribute</a>
                    </div>
                </li>

                <!-- Documentation -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-docs"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Documentation</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/papers.html">Papers</a>
                        <a class="dropdown-item"
                           href="/documentation/users">User Guide</a>
                        <a class="dropdown-item"
                           href="/documentation/developers">Developer Guide</a>
                        <a class="dropdown-item"
                           href="/docs/0.13.0/api/docs/">API Reference</a>
                        <a class="dropdown-item"
                           href="/documentation/tutorials">Tutorials and Examples</a>
                    </div>
                </li>

                <!-- Download -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-download"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Download</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/download/downloads/html">Latest Release</a>
                        <a class="dropdown-item"
                           href="https://github.com/apache/mahout/">Github Repository</a>
                        <a class="dropdown-item"
                           href="/download/quickstart">Quickstart</a>
                    </div>
                </li>

                <!-- Community -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-community"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">Community</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">

                        <a class="dropdown-item"
                           href="/community/">Overview</a>
                        <a class="dropdown-item"
                           href="/community/who-we-are.html">Who We Are</a>
                        <a class="dropdown-item"
                           href="/community/mailing-lists.html">Mailing Lists</a>
                        <a class="dropdown-item"
                           href="https://issues.apache.org/jira/browse/MAHOUT">Issue Tracker</a>
                        <a class="dropdown-item"
                           href="/documentation/developers/">Developer Documentation</a>
                        <a class="dropdown-item"
                           href="/community/coc.html">Code of Conduct</a>
                    </div>
                </li>

                <!-- News and Events -->
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle"
                       href="" id="navbarDropdownMenuLink-news-events"
                       data-toggle="dropdown"
                       aria-haspopup="true"
                       aria-expanded="false">News and Events</a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item"
                           href="/news-and-events/news.html">Latest Project News</a>
                        <a class="dropdown-item"
                           href="/news-and-events/events.html">Upcoming Events</a>
                        <a class="dropdown-item"
                           href="/news-and-events/announcements.html">Announcements</a>
                    </div>
                </li>


                <!-- GitHub -->
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/apache/mahout"><i class="fa fa-github"></i></a>
                </li>

            </ul>

            <!-- <form class="form-inline my-2 my-lg-0">
            <input class="form-control mr-sm-2" type="text" placeholder="Search" aria-label="Search">
            <button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>
        </form> -->

        </div>

    </div>

</nav>


  <p><a name="RandomForests-HowtogrowaDecisionTree"></a></p>
<h3 id="how-to-grow-a-decision-tree">How to grow a Decision Tree</h3>

<p>source : [3](3.html)</p>

<p>LearnUnprunedTree(<em>X</em>,<em>Y</em>)</p>

<p>Input: <em>X</em> a matrix of <em>R</em> rows and <em>M</em> columns where <em>X{</em>}{<em>}{~}ij{~}</em> =
the value of the <em>j</em>‘th attribute in the <em>i</em>‘th input datapoint. Each
column consists of either all real values or all categorical values.
Input: <em>Y</em> a vector of <em>R</em> elements, where <em>Y{</em>}{<em>}{~}i{~}</em> = the output
class of the <em>i</em>‘th datapoint. The <em>Y{</em>}{<em>}{~}i{~}</em> values are categorical.
Output: An Unpruned decision tree</p>

<p>If all records in <em>X</em> have identical values in all their attributes (this
includes the case where <em>R&lt;2</em>), return a Leaf Node predicting the majority
output, breaking ties randomly. This case also includes
If all values in <em>Y</em> are the same, return a Leaf Node predicting this value
as the output
Else
    select <em>m</em> variables at random out of the <em>M</em> variables
    For <em>j</em> = 1 .. <em>m</em>
        If <em>j</em>‘th attribute is
categorical
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG(<em>Y</em>|<em>X{</em>}{<em>}{~}j{~}</em>) (see Information
Gain)            
        Else (<em>j</em>‘th attribute is
real-valued)
<em>           
IG{</em>}{<em>}{~}j{~}</em> = IG<em>(</em>Y<em>|</em>X{<em>}{</em>}{~}j{~}<em>) (see Information Gain)
    Let *j*</em> = argmax{~}j~ <em>IG{</em>}{<em>}{~}j{~}</em> (this is the
splitting attribute we’ll use)
    If <em>j*</em> is categorical then
        For each value <em>v</em> of the <em>j</em>‘th
attribute
            Let
<em>X{</em>}{<em>}{^}v{^}</em> = subset of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> = <em>v</em>.
Let <em>Y{</em>}{<em>}{^}v{^}</em> = corresponding subset of <em>Y</em>
            Let <em>Child{</em>}{<em>}{^}v{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}v{^}</em>,<em>Y{</em>}{<em>}{^}v{^}</em>)
        Return a decision tree node,
splitting on <em>j</em>‘th attribute. The number of children equals the number of
values of the <em>j</em>‘th attribute, and the <em>v</em>‘th child is
<em>Child{</em>}{<em>}{^}v{^}</em>
    Else <em>j*</em> is real-valued and let <em>t</em> be the best split
threshold
        Let <em>X{</em>}{<em>}{^}LO{^}</em> = subset
of rows of <em>X</em> in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&lt;= t</em>. Let <em>Y{</em>}{<em>}{^}LO{^}</em> =
corresponding subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}LO{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}LO{^}</em>,<em>Y{</em>}{<em>}{^}LO{^}</em>)
        Let <em>X{</em>}{<em>}{^}HI{^}</em> = subset of rows of <em>X</em>
in which <em>X{</em>}{<em>}{~}ij{~}</em> <em>&gt; t</em>. Let <em>Y{</em>}{<em>}{^}HI{^}</em> = corresponding
subset of <em>Y</em>
        Let <em>Child{</em>}{<em>}{^}HI{^}</em> =
LearnUnprunedTree(<em>X{</em>}{<em>}{^}HI{^}</em>,<em>Y{</em>}{<em>}{^}HI{^}</em>)
        Return a decision tree node, splitting on
<em>j</em>‘th attribute. It has two children corresponding to whether the <em>j</em>‘th
attribute is above or below the given threshold.</p>

<p><em>Note</em>: There are alternatives to Information Gain for splitting nodes
 </p>

<p><a name="RandomForests-Informationgain"></a></p>
<h3 id="information-gain">Information gain</h3>

<p>source : [3](3.html)</p>
<ol>
  <li>h4. nominal attributes</li>
</ol>

<p>suppose X can have one of m values V{~}1~,V{~}2~,…,V{~}m~
P(X=V{~}1~)=p{~}1~, P(X=V{~}2~)=p{~}2~,…,P(X=V{~}m~)=p{~}m~
 
H(X)= -sum{~}j=1{~}{^}m^ p{~}j~ log{~}2~ p{~}j~ (The entropy of X)
H(Y|X=v) = the entropy of Y among only those records in which X has value
v
H(Y|X) = sum{~}j~ p{~}j~ H(Y|X=v{~}j~)
IG(Y|X) = H(Y) - H(Y|X)</p>
<ol>
  <li>h4. real-valued attributes</li>
</ol>

<p>suppose X is real valued
define IG(Y|X:t) as H(Y) - H(Y|X:t)
define H(Y|X:t) = H(Y|X&lt;t) P(X&lt;t) + H(Y|X&gt;=t) P(X&gt;=t)
define IG*(Y|X) = max{~}t~ IG(Y|X:t)</p>

<p><a name="RandomForests-HowtogrowaRandomForest"></a></p>
<h3 id="how-to-grow-a-random-forest">How to grow a Random Forest</h3>

<p>source : [1](1.html)</p>

<p>Each tree is grown as follows:</p>
<ol>
  <li>if the number of cases in the training set is <em>N</em>, sample <em>N</em> cases at
random -but with replacement, from the original data. This sample will be
the training set for the growing tree.</li>
  <li>if there are <em>M</em> input variables, a number <em>m « M</em> is specified such
that at each node, <em>m</em> variables are selected at random out of the <em>M</em> and
the best split on these <em>m</em> is used to split the node. The value of <em>m</em> is
held constant during the forest growing.</li>
  <li>each tree is grown to its large extent possible. There is no pruning.</li>
</ol>

<p><a name="RandomForests-RandomForestparameters"></a></p>
<h3 id="random-forest-parameters">Random Forest parameters</h3>

<p>source : [2](2.html)
Random Forests are easy to use, the only 2 parameters a user of the
technique has to determine are the number of trees to be used and the
number of variables (<em>m</em>) to be randomly selected from the available set of
variables.
Breinman’s recommendations are to pick a large number of trees, as well as
the square root of the number of variables for <em>m</em>.
 </p>

<p><a name="RandomForests-Howtopredictthelabelofacase"></a></p>
<h3 id="how-to-predict-the-label-of-a-case">How to predict the label of a case</h3>

<p>Classify(<em>node</em>,<em>V</em>)
    Input: <em>node</em> from the decision tree, if <em>node.attribute
= j</em> then the split is done on the <em>j</em>‘th attribute</p>

<p>    Input: <em>V</em> a vector of <em>M</em> columns where
<em>V{</em>}{<em>}{~}j{~}</em> = the value of the <em>j</em>‘th attribute.
    Output: label of <em>V</em></p>

<p>    If <em>node</em> is a Leaf then
            Return the value predicted
by <em>node</em></p>

<p>    Else
            Let <em>j =
node.attribute</em>
            If <em>j</em> is
categorical then
      
            
Let <em>v</em> = <em>V{</em>}{<em>}{~}j{~}</em>
      
            
Let <em>child{</em>}{<em>}{^}v{^}</em> = child node corresponding to the attribute’s
value <em>v</em>
              
     Return Classify(<em>child{</em>}{<em>}{^}v{^}</em>,<em>V</em>)</p>

<p>            Else <em>j</em> is
real-valued
      
            
Let <em>t = node.threshold</em> (split threshold)
              
     If Vj &lt; t then
                  
         Let <em>child{</em>}{<em>}{^}LO{^}</em> = child
node corresponding to (<em>&lt;t</em>)
                  
         Return
Classify(<em>child{</em>}{<em>}{^}LO{^}</em>,<em>V</em>)
      
            
Else
                  
         Let <em>child{</em>}{<em>}{^}HI{^}</em> =
child node corresponding to (<em>&gt;=t</em>)
               
            Return
Classify(<em>child{</em>}{<em>}{^}HI{^}</em>,<em>V</em>)
 </p>

<p><a name="RandomForests-Theoutofbag(oob)errorestimation"></a></p>
<h3 id="the-out-of-bag-oob-error-estimation">The out of bag (oob) error estimation</h3>

<p>source : [1](1.html)</p>

<p>in random forests, there is no need for cross-validation or a separate test
set to get an unbiased estimate of the test set error. It is estimated
internally, during the run, as follows:</p>
<ul>
  <li>each tree is constructed using a different bootstrap sample from the
original data. About one-third of the cases left of the bootstrap sample
and not used in the construction of the <em>kth</em> tree.</li>
  <li>put each case left out in the construction of the <em>kth</em> tree down the
<em>kth{</em>}tree to get a classification. In this way, a test set classification
is obtained for each case in about one-thrid of the trees. At the end of
the run, take <em>j</em> to be the class that got most of the the votes every time
case <em>n</em> was <em>oob</em>. The proportion of times that <em>j</em> is not equal to the
true class of <em>n</em> averaged over all cases is the <em>oob error estimate</em>. This
has proven to be unbiased in many tests.</li>
</ul>

<p><a name="RandomForests-OtherRFuses"></a></p>
<h3 id="other-rf-uses">Other RF uses</h3>

<p>source : [1](1.html)</p>
<ul>
  <li>variable importance</li>
  <li>gini importance</li>
  <li>proximities</li>
  <li>scaling</li>
  <li>prototypes</li>
  <li>missing values replacement for the training set</li>
  <li>missing values replacement for the test set</li>
  <li>detecting mislabeled cases</li>
  <li>detecting outliers</li>
  <li>detecting novelties</li>
  <li>unsupervised learning</li>
  <li>balancing prediction error
Please refer to [1](1.html)
 for a detailed description</li>
</ul>

<p><a name="RandomForests-References"></a></p>
<h3 id="references">References</h3>

<p>[1](1.html)
  Random Forests - Classification Description
        <a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a>
[2](2.html)
  B. Larivi�re &amp; D. Van Den Poel, 2004. “Predicting Customer Retention
and Profitability by Using Random Forests and Regression Forests
Techniques,”
        Working Papers of Faculty of
Economics and Business Administration, Ghent University, Belgium 04/282,
Ghent University,
        Faculty of Economics and
Business Administration.
        Available online : <a href="http://ideas.repec.org/p/rug/rugwps/04-282.html">http://ideas.repec.org/p/rug/rugwps/04-282.html</a>
[3](3.html)
  Decision Trees - Andrew W. Moore[4]
        http://www.cs.cmu.edu/~awm/tutorials[1](1.html)
[4](4.html)
  Information Gain - Andrew W. Moore
        <a href="http://www.cs.cmu.edu/~awm/tutorials">http://www.cs.cmu.edu/~awm/tutorials</a></p>


  <footer class="footer bg-light">
    <div class="container text-center small">
        Copyright &copy; 2014-2024 <a href="http://www.apache.org/">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
    </div>
</footer>


  <script src="/assets/vendor/jquery/jquery-slim.min.js"></script>
  <script src="/assets/vendor/popper/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap/js/bootstrap.min.js"></script>
  <script src="/assets/header.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</body>

</html>
