<div style="background-color: #fff3cd; color: #856404; border: 1px solid #ffeeba; padding: 15px; border-radius: 5px; margin-bottom: 20px;"> <strong>⚠️ Deprecation Notice:</strong> This component (<em>Map Reduce</em>) is no longer actively maintained. It remains accessible for historical reference but is not recommended for new development.  Please check out <a href="https://mahout.apache.org/quantum-computing-primer/" style="color: #0c5460; text-decoration: underline;">Qumat - Mahout's Quantum Computing Primer</a> for the latest innovations.</div>

<p><a name="canopy-commandline-RunningCanopyClusteringfromtheCommandLine"></a></p>
<h1 id="running-canopy-clustering-from-the-command-line">Running Canopy Clustering from the Command Line</h1>
<p>Mahout’s Canopy clustering can be launched from the same command line
invocation whether you are running on a single machine in stand-alone mode
or on a larger Hadoop cluster. The difference is determined by the
$HADOOP_HOME and $HADOOP_CONF_DIR environment variables. If both are set to
an operating Hadoop cluster on the target machine then the invocation will
run Canopy on that cluster. If either of the environment variables are
missing then the stand-alone Hadoop configuration will be invoked instead.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/mahout canopy &lt;OPTIONS&gt;
</code></pre></div></div>

<ul>
  <li>In $MAHOUT_HOME/, build the jar containing the job (mvn install) The job
will be generated in $MAHOUT_HOME/core/target/ and it’s name will contain
the Mahout version number. For example, when using Mahout 0.3 release, the
job will be mahout-core-0.3.job</li>
</ul>

<p><a name="canopy-commandline-Testingitononesinglemachinew/ocluster"></a></p>
<h2 id="testing-it-on-one-single-machine-wo-cluster">Testing it on one single machine w/o cluster</h2>

<ul>
  <li>Put the data: cp <PATH TO="" DATA=""> testdata</PATH></li>
  <li>
    <p>Run the Job:</p>

    <p>./bin/mahout canopy -i testdata -o output -dm
org.apache.mahout.common.distance.CosineDistanceMeasure -ow -t1 5 -t2 2</p>
  </li>
</ul>

<p><a name="canopy-commandline-Runningitonthecluster"></a></p>
<h2 id="running-it-on-the-cluster">Running it on the cluster</h2>

<ul>
  <li>(As needed) Start up Hadoop: $HADOOP_HOME/bin/start-all.sh</li>
  <li>Put the data: $HADOOP_HOME/bin/hadoop fs -put <PATH TO="" DATA=""> testdata</PATH></li>
  <li>
    <p>Run the Job:</p>

    <p>export HADOOP_HOME=<Hadoop Home="" Directory="">
  export HADOOP_CONF_DIR=$HADOOP_HOME/conf
  ./bin/mahout canopy -i testdata -o output -dm
org.apache.mahout.common.distance.CosineDistanceMeasure -ow -t1 5 -t2 2</Hadoop></p>
  </li>
  <li>Get the data out of HDFS and have a look. Use bin/hadoop fs -lsr output
to view all outputs.</li>
</ul>

<p><a name="canopy-commandline-Commandlineoptions"></a></p>
<h1 id="command-line-options">Command line options</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  --input (-i) input			     Path to job input directory.Must  
					     be a SequenceFile of	    
					     VectorWritable		    
  --output (-o) output			     The directory pathname for output. 
  --overwrite (-ow)			     If present, overwrite the output	 
					     directory before running job   
  --distanceMeasure (-dm) distanceMeasure    The classname of the	    
					     DistanceMeasure. Default is    
					     SquaredEuclidean		    
  --t1 (-t1) t1 			     T1 threshold value 	    
  --t2 (-t2) t2 			     T2 threshold value 	    
  --clustering (-cl)			     If present, run clustering after	
					     the iterations have taken place	 
  --help (-h)				     Print out help		    
</code></pre></div></div>

