<div style="background-color: #fff3cd; color: #856404; border: 1px solid #ffeeba; padding: 15px; border-radius: 5px; margin-bottom: 20px;"> <strong>⚠️ Deprecation Notice:</strong> This component (<em>Map Reduce</em>) is no longer actively maintained. It remains accessible for historical reference but is not recommended for new development.  Please check out <a href="https://mahout.apache.org/quantum-computing-primer/" style="color: #0c5460; text-decoration: underline;">Qumat - Mahout's Quantum Computing Primer</a> for the latest innovations.</div>

<p><a name="PerceptronandWinnow-ClassificationwithPerceptronorWinnow"></a></p>
<h1 id="classification-with-perceptron-or-winnow">Classification with Perceptron or Winnow</h1>

<p>Both algorithms are comparably simple linear classifiers. Given training
data in some n-dimensional vector space that is annotated with binary
labels the algorithms are guaranteed to find a linear separating hyperplane
if one exists. In contrast to the Perceptron, Winnow works only for binary
feature vectors.</p>

<p>For more information on the Perceptron see for instance:
http://en.wikipedia.org/wiki/Perceptron</p>

<p>Concise course notes on both algorithms:
http://pages.cs.wisc.edu/~shuchi/courses/787-F07/scribe-notes/lecture24.pdf</p>

<p>Although the algorithms are comparably simple they still work pretty well
for text classification and are fast to train even for huge example sets.
In contrast to Naive Bayes they are not based on the assumption that all
features (in the domain of text classification: all terms in a document)
are independent.</p>

<p><a name="PerceptronandWinnow-Strategyforparallelisation"></a></p>
<h2 id="strategy-for-parallelisation">Strategy for parallelisation</h2>

<p>Currently the strategy for parallelisation is simple: Given there is enough
training data, split the training data. Train the classifier on each split.
The resulting hyperplanes are then averaged.</p>

<p><a name="PerceptronandWinnow-Roadmap"></a></p>
<h2 id="roadmap">Roadmap</h2>

<p>Currently the patch only contains the code for the classifier itself. It is
planned to provide unit tests and at least one example based on the WebKB
dataset by the end of November for the serial version. After that the
parallelisation will be added.</p>
