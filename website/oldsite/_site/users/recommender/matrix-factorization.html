

<!DOCTYPE html>
<!--

    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
    this work for additional information regarding copyright ownership.
    The ASF licenses this file to You under the Apache License, Version 2.0
    (the "License"); you may not use this file except in compliance with
    the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
-->

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Apache Mahout: Scalable machine learning and data mining</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="Distribution" content="Global">
  <meta name="Robots" content="index,follow">
  <meta name="keywords" content="apache, apache hadoop, apache lucene,
        business data mining, cluster analysis,
        collaborative filtering, data extraction, data filtering, data framework, data integration,
        data matching, data mining, data mining algorithms, data mining analysis, data mining data,
        data mining introduction, data mining software,
        data mining techniques, data representation, data set, datamining,
        feature extraction, fuzzy k means, genetic algorithm, hadoop,
        hierarchical clustering, high dimensional, introduction to data mining, kmeans,
        knowledge discovery, learning approach, learning approaches, learning methods,
        learning techniques, lucene, machine learning, machine translation, mahout apache,
        mahout taste, map reduce hadoop, mining data, mining methods, naive bayes,
        natural language processing,
        supervised, text mining, time series data, unsupervised, web data mining">
  <link rel="shortcut icon" type="image/x-icon" href="https://mahout.apache.org/images/favicon.ico">
  <!--<script type="text/javascript" src="/js/prototype.js"></script>-->
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/prototype/1.7.2.0/prototype.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/effects.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/search.js"></script>
  <script type="text/javascript" src="/assets/themes/mahout-retro/js/slides.js"></script>

  <link href="/assets/themes/mahout-retro/css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="/assets/themes/mahout-retro/css/bootstrap-responsive.css" rel="stylesheet">
  <link rel="stylesheet" href="/assets/themes/mahout-retro/css/global.css" type="text/css">

  <!-- mathJax stuff -- use `\(...\)` for inline style math in markdown -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  </script>
  <script type="text/javascript">
    var mathjax = document.createElement('script'); 
    mathjax.type = 'text/javascript'; 
    mathjax.async = true;

    mathjax.src = ('https:' == document.location.protocol) ?
        'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' : 
        'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
	
	  var s = document.getElementsByTagName('script')[0]; 
    s.parentNode.insertBefore(mathjax, s);
  </script>
</head>

<body id="home" data-twttr-rendered="true">
  <div id="wrap">
   <div id="header">
    <div id="logo"><a href="/"><img src="/assets/img/mahout-logo-brudman.png" alt="Logos for Mahout and Apache Software Foundation" /></a></div>
  <div id="search">
    <form id="search-form" action="http://www.google.com/search" method="get" class="navbar-search pull-right">    
      <input value="http://mahout.apache.org" name="sitesearch" type="hidden">
      <input class="search-query" name="q" id="query" type="text">
      <input id="submission" type="image" src="/assets/img/mahout-lupe.png" alt="Search" />
    </form>
  </div>
 
    <div class="navbar navbar-inverse" style="position:absolute;top:133px;padding-right:0px;padding-left:0px;">
      <div class="navbar-inner" style="border: none; background: #999; border: none; border-radius: 0px;">
        <div class="container">
          <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- <a class="brand" href="#">Apache Community Development Project</a> -->
            <!--<div class="nav-collapse collapse">-->
<div class="collapse navbar-collapse" id="main-navbar">
    <ul class="nav navbar-nav">
        <!-- <li><a href="/">Home</a></li> -->
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">General<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/general/downloads.html">Downloads</a>
                <li><a href="/general/who-we-are.html">Who we are</a>
                <li><a href="/general/mailing-lists,-irc-and-archives.html">Mailing Lists</a>
                <li><a href="/general/release-notes.html">Release Notes</a>
                <li><a href="/general/books-tutorials-and-talks.html">Books, Tutorials, Talks</a></li>
                <li><a href="/general/powered-by-mahout.html">Powered By Mahout</a>
                <li><a href="/general/professional-support.html">Professional Support</a>
                <li class="divider"></li>
                <li class="nav-header">Resources</li>
                <li><a href="/general/reference-reading.html">Reference Reading</a>
                <li><a href="/general/faq.html">FAQ</a>
                <li class="divider"></li>
                <li class="nav-header">Legal</li>
                <li><a href="http://www.apache.org/licenses/">License</a></li>
                <li><a href="http://www.apache.org/security/">Security</a></li>
                <li><a href="/general/privacy-policy.html">Privacy Policy</a>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Developers<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/developers/developer-resources.html">Developer resources</a></li>
                <li><a href="/developers/version-control.html">Version control</a></li>
                <li><a href="/developers/buildingmahout.html">Build from source</a></li>
                <li><a href="/developers/issue-tracker.html">Issue tracker</a></li>
                <li><a href="https://builds.apache.org/job/Mahout-Quality/" target="_blank">Code quality reports</a></li>
                <li class="divider"></li>
                <li class="nav-header">Contributions</li>
                <li><a href="/developers/how-to-contribute.html">How to contribute</a></li>
                <li><a href="/developers/how-to-become-a-committer.html">How to become a committer</a></li>
                <li><a href="/developers/gsoc.html">GSoC</a></li>
                <li class="divider"></li>
                <li class="nav-header">For committers</li>
                <li><a href="/developers/how-to-update-the-website.html">How to update the website</a></li>
                <li><a href="/developers/patch-check-list.html">Patch check list</a></li>
                <li><a href="/developers/github.html">Handling Github PRs</a></li>
                <li><a href="/developers/how-to-release.html">How to release</a></li>
                <li><a href="/developers/thirdparty-dependencies.html">Third party dependencies</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout-Samsara<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/sparkbindings/home.html">Scala &amp; Spark Bindings Overview</a></li>
                <li><a href="/users/sparkbindings/faq.html">FAQ</a></li>
                <li><a href="/users/flinkbindings/playing-with-samsara-flink.html">Flink Bindings Overview</a></li>
                <li class="nav-header">Engines</li>
                <li><a href="/users/sparkbindings/home.html">Spark</a></li>
                <li><a href="/users/environment/h2o-internals.html">H2O</a></li>
                <li><a href="/users/flinkbindings/flink-internals.html">Flink</a></li>
                <li class="nav-header">References</li>
                <li><a href="/users/environment/in-core-reference.html">In-Core Algebraic DSL Reference</a></li>
                <li><a href="/users/environment/out-of-core-reference.html">Distributed Algebraic DSL Reference</a></li>
                <li class="nav-header">Tutorials</li>
                <li><a href="/users/sparkbindings/play-with-shell.html">Playing with Mahout's Spark Shell</a></li>
                <li><a href="/users/environment/how-to-build-an-app.html">How to build an app</a></li>
                <li><a href="/users/environment/classify-a-doc-from-the-shell.html">Building a text classifier in Mahout's Spark Shell</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithms<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li class="nav-header">Distributed Matrix Decomposition</li>
                <li><a href="/users/algorithms/d-qr.html">Cholesky QR</a></li>
                <li><a href="/users/algorithms/d-ssvd.html">SSVD</a></li>
                <li><a href="/users/algorithms/d-als.html">Distributed ALS</a></li>
                <li><a href="/users/algorithms/d-spca.html">SPCA</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/algorithms/recommender-overview.html">Recommender Overview</a></li>
                <li><a href="/users/algorithms/intro-cooccurrence-spark.html">Intro to cooccurrence-based<br/> recommendations with Spark</a></li>
                <li class="nav-header">Classification</li>
                <li><a href="/users/algorithms/spark-naive-bayes.html">Spark Naive Bayes</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">MapReduce Basics<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li><a href="/users/basics/algorithms.html">List of algorithms</a>
                <li><a href="/users/basics/quickstart.html">Overview</a>
                <li class="divider"></li>
                <li class="nav-header">Working with text</li>
                <li><a href="/users/basics/creating-vectors-from-text.html">Creating vectors from text</a>
                <li><a href="/users/basics/collocations.html">Collocations</a>
                <li class="divider"></li>
                <li class="nav-header">Dimensionality reduction</li>
                <li><a href="/users/dim-reduction/dimensional-reduction.html">Singular Value Decomposition</a></li>
                <li><a href="/users/dim-reduction/ssvd.html">Stochastic SVD</a></li>
                <li class="divider"></li>
                <li class="nav-header">Topic Models</li>
                <li><a href="/users/clustering/latent-dirichlet-allocation.html">Latent Dirichlet Allocation</a></li>
            </ul>
        </li>
        <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Mahout MapReduce<b class="caret"></b></a>
            <ul class="dropdown-menu">
                <li class="nav-header">Classification</li>
                <li><a href="/users/classification/bayesian.html">Naive Bayes</a></li>
                <li><a href="/users/classification/hidden-markov-models.html">Hidden Markov Models</a></li>
                <li><a href="/users/classification/logistic-regression.html">Logistic Regression (Single Machine)</a></li>
                <li><a href="/users/classification/partial-implementation.html">Random Forest</a></li>
                <li class="nav-header">Classification Examples</li>
                <li><a href="/users/classification/breiman-example.html">Breiman example</a></li>
                <li><a href="/users/classification/twenty-newsgroups.html">20 newsgroups example</a></li>
                <li><a href="/users/classification/bankmarketing-example.html">SGD classifier bank marketing</a></li>
                <li><a href="/users/classification/wikipedia-classifier-example.html">Wikipedia XML parser and classifier</a></li>
                <li class="nav-header">Clustering</li>
                <li><a href="/users/clustering/k-means-clustering.html">k-Means</a></li>
                <li><a href="/users/clustering/canopy-clustering.html">Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means.html">Fuzzy k-Means</a></li>
                <li><a href="/users/clustering/streaming-k-means.html">Streaming KMeans</a></li>
                <li><a href="/users/clustering/spectral-clustering.html">Spectral Clustering</a></li>
                <li class="nav-header">Clustering Commandline usage</li>
                <li><a href="/users/clustering/k-means-commandline.html">Options for k-Means</a></li>
                <li><a href="/users/clustering/canopy-commandline.html">Options for Canopy</a></li>
                <li><a href="/users/clustering/fuzzy-k-means-commandline.html">Options for Fuzzy k-Means</a></li>
                <li class="nav-header">Clustering Examples</li>
                <li><a href="/users/clustering/clustering-of-synthetic-control-data.html">Synthetic data</a></li>
                <li class="nav-header">Cluster Post processing</li>
                <li><a href="/users/clustering/cluster-dumper.html">Cluster Dumper tool</a></li>
                <li><a href="/users/clustering/visualizing-sample-clusters.html">Cluster visualisation</a></li>
                <li class="nav-header">Recommendations</li>
                <li><a href="/users/recommender/recommender-first-timer-faq.html">First Timer FAQ</a></li>
                <li><a href="/users/recommender/userbased-5-minutes.html">A user-based recommender <br/>in 5 minutes</a></li>
                <li><a href="/users/recommender/matrix-factorization.html">Matrix factorization-based<br/> recommenders</a></li>
                <li><a href="/users/recommender/recommender-documentation.html">Overview</a></li>
                <li><a href="/users/recommender/intro-itembased-hadoop.html">Intro to item-based recommendations<br/> with Hadoop</a></li>
                <li><a href="/users/recommender/intro-als-hadoop.html">Intro to ALS recommendations<br/> with Hadoop</a></li>
            </ul>
        </li>
        <!--  <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown">Recommendations<b class="caret"></b></a>
          <ul class="dropdown-menu">

          </ul> -->
        </li>
    </ul>
</div><!--/.nav-collapse -->
        </div>
      </div>
    </div>

</div>

 <div id="sidebar">
  <div id="sidebar-wrap">
    <h2>Twitter</h2>
	<ul class="sidemenu">
		<li>
<a class="twitter-timeline" href="https://twitter.com/ApacheMahout" data-widget-id="422861673444028416">Tweets by @ApacheMahout</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</li>
	</ul>
    <h2>Apache Software Foundation</h2>
    <ul class="sidemenu">
      <li><a href="http://www.apache.org/foundation/how-it-works.html">How the ASF works</a></li>
      <li><a href="http://www.apache.org/foundation/getinvolved.html">Get Involved</a></li>
      <li><a href="http://www.apache.org/dev/">Developer Resources</a></li>
      <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
      <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
    </ul>
    <h2>Related Projects</h2>
    <ul class="sidemenu">
      <li><a href="http://lucene.apache.org/">Apache Lucene</a></li>
      <li><a href="http://hadoop.apache.org/">Apache Hadoop</a></li>
      <li><a href="http://bigtop.apache.org/">Apache Bigtop</a></li>
      <li><a href="http://spark.apache.org/">Apache Spark</a></li>
	  <li><a href="http://flink.apache.org/">Apache Flink</a></li>
    </ul>
  </div>
</div>

  <div id="content-wrap" class="clearfix">
   <div id="main">

    <p><a name="MatrixFactorization-Intro"></a></p>
<h1 id="introduction-to-matrix-factorization-for-recommendation-mining">Introduction to Matrix Factorization for Recommendation Mining</h1>

<p>In the mathematical discipline of linear algebra, a matrix decomposition 
or matrix factorization is a dimensionality reduction technique that factorizes a matrix into a product of matrices, usually two. 
There are many different matrix decompositions, each finds use among a particular class of problems.</p>

<p>In mahout, the SVDRecommender provides an interface to build recommender based on matrix factorization.
The idea behind is to project the users and items onto a feature space and try to optimize U and M so that U * (M^t) is as close to R as possible:</p>

<div class="highlighter-rouge"><pre class="highlight"><code> U is n * p user feature matrix, 
 M is m * p item feature matrix, M^t is the conjugate transpose of M,
 R is n * m rating matrix,
 n is the number of users,
 m is the number of items,
 p is the number of features
</code></pre>
</div>

<p>We usually use RMSE to represent the deviations between predictions and atual ratings.
RMSE is defined as the squared root of the sum of squared errors at each known user item ratings.
So our matrix factorization target could be mathmatically defined as:</p>

<div class="highlighter-rouge"><pre class="highlight"><code> find U and M, (U, M) = argmin(RMSE) = argmin(pow(SSE / K, 0.5))
 
 SSE = sum(e(u,i)^2)
 e(u,i) = r(u, i) - U[u,] * (M[i,]^t) = r(u,i) - sum(U[u,f] * M[i,f]), f = 0, 1, .. p - 1
 K is the number of known user item ratings.
</code></pre>
</div>

<p><a name="MatrixFactorization-Factorizers"></a></p>

<p>Mahout has implemented matrix factorization based on</p>

<div class="highlighter-rouge"><pre class="highlight"><code>(1) SGD(Stochastic Gradient Descent)
(2) ALSWR(Alternating-Least-Squares with Weighted-λ-Regularization).
</code></pre>
</div>

<h2 id="sgd">SGD</h2>

<p>Stochastic gradient descent is a gradient descent optimization method for minimizing an objective function that is written as a su of differentiable functions.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>   Q(w) = sum(Q_i(w)), 
</code></pre>
</div>

<p>where w is the parameters to be estimated,
      Q(w) is the objective function that could be expressed as sum of differentiable functions,
      Q_i(w) is associated with the i-th observation in the data set</p>

<p>In practice, w is estimated using an iterative method at each single sample until an approximate miminum is obtained,</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  w = w - alpha * (d(Q_i(w))/dw), where aplpha is the learning rate,
  (d(Q_i(w))/dw) is the first derivative of Q_i(w) on w.
</code></pre>
</div>

<p>In matrix factorization, the RatingSGDFactorizer class implements the SGD with w = (U, M) and objective function Q(w) = sum(Q(u,i)),</p>

<div class="highlighter-rouge"><pre class="highlight"><code>   Q(u,i) =  sum(e(u,i) * e(u,i)) / 2 + lambda * [(U[u,] * (U[u,]^t)) + (M[i,] * (M[i,]^t))] / 2
</code></pre>
</div>

<p>where Q(u, i) is the objecive function for user u and item i,
      e(u, i) is the error between predicted rating and actual rating,
      U[u,] is the feature vector of user u,
      M[i,] is the feature vector of item i,
      lambda is the regularization parameter to prevent overfitting.</p>

<p>The algorithm is sketched as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  init U and M with randomized value between 0.0 and 1.0 with standard Gaussian distribution   
  
  for(iter = 0; iter &lt; numIterations; iter++)
  {
      for(user u and item i with rating R[u,i])
      {
          predicted_rating = U[u,] *  M[i,]^t //dot product of feature vectors between user u and item i
          err = R[u, i] - predicted_rating
          //adjust U[u,] and M[i,]
          // p is the number of features
          for(f = 0; f &lt; p; f++) {
             NU[u,f] = U[u,f] - alpha * d(Q(u,i))/d(U[u,f]) //optimize U[u,f]
                     = U[u, f] + alpha * (e(u,i) * M[i,f] - lambda * U[u,f]) 
          }
          for(f = 0; f &lt; p; f++) {
             M[i,f] = M[i,f] - alpha * d(Q(u,i))/d(M[i,f])  //optimize M[i,f] 
                    = M[i,f] + alpha * (e(u,i) * U[u,f] - lambda * M[i,f]) 
          }
          U[u,] = NU[u,]
      }
  }
</code></pre>
</div>

<h2 id="svd">SVD++</h2>

<p>SVD++ is an enhancement of the SGD matrix factorization.</p>

<p>It could be considered as an integration of latent factor model and neighborhood based model, considering not only how users rate, but also who has rated what.</p>

<p>The complete model is a sum of 3 sub-models with complete prediction formula as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>pr(u,i) = b[u,i] + fm + nm   //user u and item i

pr(u,i) is the predicted rating of user u on item i,
b[u,i] = U + b(u) + b(i)
fm = (q[i,]) * (p[u,] + pow(|N(u)|, -0.5) * sum(y[j,])),  j is an item in N(u)
nm = pow(|R(i;u;k)|, -0.5) * sum((r[u,j0] - b[u,j0]) * w[i,j0]) + pow(|N(i;u;k)|, -0.5) * sum(c[i,j1]), j0 is an item in R(i;u;k), j1 is an item in N(i;u;k)
</code></pre>
</div>

<p>The associated regularized squared error function to be minimized is:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="err">sum((r[u,i]</span><span class="w"> </span><span class="err">-</span><span class="w"> </span><span class="err">pr[u,i])</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">(r[u,i]</span><span class="w"> </span><span class="err">-</span><span class="w"> </span><span class="err">pr[u,i]))</span><span class="w">  </span><span class="err">-</span><span class="w"> </span><span class="err">lambda</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">(b(u)</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">b(u)</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">b(i)</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">b(i)</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">||q[i,]||^2</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">||p[u,]||^2</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">sum(||y[j,]||^2)</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">sum(w[i,j0]</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">w[i,j0])</span><span class="w"> </span><span class="err">+</span><span class="w"> </span><span class="err">sum(c[i,j1]</span><span class="w"> </span><span class="err">*</span><span class="w"> </span><span class="err">c[i,j1]))</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>b[u,i] is the baseline estimate of user u’s predicted rating on item i. U is users’ overall average rating and b(u) and b(i) indicate the observed deviations of user u and item i’s ratings from average.</p>

<p>The baseline estimate is to adjust for the user and item effects - i.e, systematic tendencies for some users to give higher ratings than others and tendencies
for some items to receive higher ratings than other items.</p>

<p>fm is the latent factor model to capture the interactions between user and item via a feature layer. q[i,] is the feature vector of item i, and the rest part of the formula represents user u with a user feature vector and a sum of features of items in N(u),
N(u) is the set of items that user u have expressed preference, y[j,] is feature vector of an item in N(u).</p>

<p>nm is an extension of the classic item-based neighborhood model. 
It captures not only the user’s explicit ratings but also the user’s implicit preferences. R(i;u;k) is the set of items that have got explicit rating from user u and only retain top k most similar items. r[u,j0] is the actual rating of user u on item j0, 
b[u,j0] is the corresponding baseline estimate.</p>

<p>The difference between r[u,j0] and b[u,j0] is weighted by a parameter w[i,j0], which could be thought as the similarity between item i and j0.</p>

<p>N[i;u;k] is the top k most similar items that have got the user’s preference.
c[i;j1] is the paramter to be estimated.</p>

<p>The value of w[i,j0] and c[i,j1] could be treated as the significance of the 
user’s explicit rating and implicit preference respectively.</p>

<p>The parameters b, y, q, w, c are to be determined by minimizing the the associated regularized squared error function through gradient descent. We loop over all known ratings and for a given training case r[u,i], we apply gradient descent on the error function and modify the parameters by moving in the opposite direction of the gradient.</p>

<p>For a complete analysis of the SVD++ algorithm,
please refer to the paper <a href="http://research.yahoo.com/files/kdd08koren.pdf">Yehuda Koren: Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model, KDD 2008</a>.</p>

<table>
  <tbody>
    <tr>
      <td>In Mahout,SVDPlusPlusFactorizer class is a simplified implementation of the SVD++ algorithm.It mainly uses the latent factor model with item feature vector, user feature vector and user’s preference, with pr(u,i) = fm = (q[i,]) * (p[u,] + pow(</td>
      <td>N(u)</td>
      <td>, -0.5) * sum(y[j,])) and the parameters to be determined are q, p, y.</td>
    </tr>
  </tbody>
</table>

<p>The update to q, p, y in each gradient descent step is:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  err(u,i) = r[u,i] - pr[u,i]
  q[i,] = q[i,] + alpha * (err(u,i) * (p[u,] + pow(|N(u)|, -0.5) * sum(y[j,])) - lamda * q[i,]) 
  p[u,] = p[u,] + alpha * (err(u,i) * q[i,] - lambda * p[u,])
  for j that is an item in N(u):
     y[j,] = y[j,] + alpha * (err(u,i) * pow(|N(u)|, -0.5) * q[i,] - lambda * y[j,])
</code></pre>
</div>

<p>where alpha is the learning rate of gradient descent, N(u) is the items that user u has expressed preference.</p>

<h2 id="parallel-sgd">Parallel SGD</h2>

<p>Mahout has a parallel SGD implementation in ParallelSGDFactorizer class. It shuffles the user ratings in every iteration and 
generates splits on the shuffled ratings. Each split is handled by a thread to update the user features and item features using 
vanilla SGD.</p>

<p>The implementation could be traced back to a lock-free version of SGD based on paper 
<a href="http://www.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf">Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a>.</p>

<h2 id="alswr">ALSWR</h2>

<p>ALSWR is an iterative algorithm to solve the low rank factorization of user feature matrix U and item feature matrix M.<br />
The loss function to be minimized is formulated as the sum of squared errors plus <a href="http://en.wikipedia.org/wiki/Tikhonov_regularization">Tikhonov regularization</a>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code> L(R, U, M) = sum(pow((R[u,i] - U[u,]* (M[i,]^t)), 2)) + lambda * (sum(n(u) * ||U[u,]||^2) + sum(n(i) * ||M[i,]||^2))
</code></pre>
</div>

<p>At the beginning of the algorithm, M is initialized with the average item ratings as its first row and random numbers for the rest row.</p>

<p>In every iteration, we fix M and solve U by minimization of the cost function L(R, U, M), then we fix U and solve M by the minimization of 
the cost function similarly. The iteration stops until a certain stopping criteria is met.</p>

<p>To solve the matrix U when M is given, each user’s feature vector is calculated by resolving a regularized linear least square error function 
using the items the user has rated and their feature vectors:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  1/2 * d(L(R,U,M)) / d(U[u,f]) = 0 
</code></pre>
</div>

<p>Similary, when M is updated, we resolve a regularized linear least square error function using feature vectors of the users that have rated the 
item and their feature vectors:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  1/2 * d(L(R,U,M)) / d(M[i,f]) = 0
</code></pre>
</div>

<p>The ALSWRFactorizer class is a non-distributed implementation of ALSWR using multi-threading to dispatch the computation among several threads.
Mahout also offers a <a href="https://mahout.apache.org/users/recommender/intro-als-hadoop.html">parallel map-reduce implementation</a>.</p>

<p><a name="MatrixFactorization-Reference"></a></p>
<h1 id="reference">Reference:</h1>

<p><a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a></p>

<p><a href="http://www.hpl.hp.com/personal/Robert_Schreiber/papers/2008%20AAIM%20Netflix/netflix_aaim08%28submitted%29.pdf">ALSWR</a></p>


   </div>
  </div>     
</div> 
  <footer class="footer" align="center">
    <div class="container">
      <p>
        Copyright &copy; 2014-2016 The Apache Software Foundation, Licensed under
        the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a>.
        <br />
		  Apache Mahout, Mahout, Apache, the Apache feather logo, and the elephant rider logo are either registered trademarks or trademarks of <a href="http://www.apache.org/foundation/marks/">The Apache Software Foundation</a> in the United States and other countries.
      </p>
    </div>
  </footer>
  
  <script src="/assets/themes/mahout-retro/js/jquery-1.9.1.min.js"></script>
  <script src="/assets/themes/mahout-retro/js/bootstrap.min.js"></script>
  <script>
    (function() {
      var cx = '012254517474945470291:vhsfv7eokdc';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
          '//www.google.com/cse/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
</body>
</html>

